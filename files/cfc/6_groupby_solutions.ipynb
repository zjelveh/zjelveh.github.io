{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f75513f",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zjelveh/zjelveh.github.io/blob/master/files/cfc/6_groupby_solutions.ipynb)\n",
    "\n",
    "**IMPORTANT**: Save your own copy!\n",
    "1. Click File â†’ Save a copy in Drive\n",
    "2. Rename it\n",
    "3. Work in YOUR copy, not the original\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Groupby and Aggregation - SOLUTIONS\n",
    "## CCJS 418E: Coding for Criminology\n",
    "\n",
    "This notebook contains worked solutions for Lab 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd004d0",
   "metadata": {},
   "source": [
    "## Part 1: The Problem We Can't Answer Yet\n",
    "\n",
    "### When Filtering Isn't Enough\n",
    "\n",
    "Imagine you're working for the Department of Justice. They need to know:\n",
    "- Which 5 states have the highest average violent crime rates over the past decade?\n",
    "- Are crime rates increasing or decreasing in each state?\n",
    "- Which regions of the country have different crime patterns?\n",
    "\n",
    "We know how to filter for specific states or years, but how do we calculate statistics for EACH state or EACH year separately? This is where **groupby** becomes essential.\n",
    "\n",
    "**Connection to Computational Thinking: PATTERN RECOGNITION - finding patterns within categories of data**\n",
    "\n",
    "Let's start by loading our familiar state crime data and seeing why filtering alone isn't sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cd8529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:09.191347Z",
     "iopub.status.busy": "2025-10-23T04:50:09.190696Z",
     "iopub.status.idle": "2025-10-23T04:50:10.005709Z",
     "shell.execute_reply": "2025-10-23T04:50:10.004048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3115 records covering 1960 to 2019\n",
      "Number of states: 52\n"
     ]
    }
   ],
   "source": [
    "# Import pandas as always\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "# Load the state crime data we've been using\n",
    "url = 'https://raw.githubusercontent.com/zjelveh/zjelveh.github.io/refs/heads/master/files/cfc/state_crime.csv'\n",
    "df = pd.read_csv(filepath_or_buffer=url)\n",
    "\n",
    "# Clean column names like before - making them easier to work with\n",
    "df.columns = df.columns.str.replace('^Data.', '', regex=True)\n",
    "df.columns = df.columns.str.replace('\\\\.', '_', regex=True).str.lower()\n",
    "# Clean up column names one more time\n",
    "df.columns = df.columns.str.replace('rates_', '')\n",
    "\n",
    "\n",
    "print(f\"We have {len(df)} records covering {df['year'].min()} to {df['year'].max()}\")\n",
    "print(f\"Number of states: {df['state'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4042d9bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.011491Z",
     "iopub.status.busy": "2025-10-23T04:50:10.010901Z",
     "iopub.status.idle": "2025-10-23T04:50:10.058594Z",
     "shell.execute_reply": "2025-10-23T04:50:10.056726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>property_all</th>\n",
       "      <th>property_burglary</th>\n",
       "      <th>property_larceny</th>\n",
       "      <th>property_motor</th>\n",
       "      <th>violent_all</th>\n",
       "      <th>violent_assault</th>\n",
       "      <th>violent_murder</th>\n",
       "      <th>violent_rape</th>\n",
       "      <th>violent_robbery</th>\n",
       "      <th>totals_property_all</th>\n",
       "      <th>totals_property_burglary</th>\n",
       "      <th>totals_property_larceny</th>\n",
       "      <th>totals_property_motor</th>\n",
       "      <th>totals_violent_all</th>\n",
       "      <th>totals_violent_assault</th>\n",
       "      <th>totals_violent_murder</th>\n",
       "      <th>totals_violent_rape</th>\n",
       "      <th>totals_violent_robbery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1960</td>\n",
       "      <td>3266740</td>\n",
       "      <td>1035.4</td>\n",
       "      <td>355.9</td>\n",
       "      <td>592.1</td>\n",
       "      <td>87.3</td>\n",
       "      <td>186.6</td>\n",
       "      <td>138.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>27.5</td>\n",
       "      <td>33823</td>\n",
       "      <td>11626</td>\n",
       "      <td>19344</td>\n",
       "      <td>2853</td>\n",
       "      <td>6097</td>\n",
       "      <td>4512</td>\n",
       "      <td>406</td>\n",
       "      <td>281</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1961</td>\n",
       "      <td>3302000</td>\n",
       "      <td>985.5</td>\n",
       "      <td>339.3</td>\n",
       "      <td>569.4</td>\n",
       "      <td>76.8</td>\n",
       "      <td>168.5</td>\n",
       "      <td>128.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>32541</td>\n",
       "      <td>11205</td>\n",
       "      <td>18801</td>\n",
       "      <td>2535</td>\n",
       "      <td>5564</td>\n",
       "      <td>4255</td>\n",
       "      <td>427</td>\n",
       "      <td>252</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1962</td>\n",
       "      <td>3358000</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>349.1</td>\n",
       "      <td>634.5</td>\n",
       "      <td>83.4</td>\n",
       "      <td>157.3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>35829</td>\n",
       "      <td>11722</td>\n",
       "      <td>21306</td>\n",
       "      <td>2801</td>\n",
       "      <td>5283</td>\n",
       "      <td>3995</td>\n",
       "      <td>316</td>\n",
       "      <td>218</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1963</td>\n",
       "      <td>3347000</td>\n",
       "      <td>1150.9</td>\n",
       "      <td>376.9</td>\n",
       "      <td>683.4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>182.7</td>\n",
       "      <td>142.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>38521</td>\n",
       "      <td>12614</td>\n",
       "      <td>22874</td>\n",
       "      <td>3033</td>\n",
       "      <td>6115</td>\n",
       "      <td>4755</td>\n",
       "      <td>340</td>\n",
       "      <td>192</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1964</td>\n",
       "      <td>3407000</td>\n",
       "      <td>1358.7</td>\n",
       "      <td>466.6</td>\n",
       "      <td>784.1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>213.1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>29.1</td>\n",
       "      <td>46290</td>\n",
       "      <td>15898</td>\n",
       "      <td>26713</td>\n",
       "      <td>3679</td>\n",
       "      <td>7260</td>\n",
       "      <td>5555</td>\n",
       "      <td>316</td>\n",
       "      <td>397</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>586107</td>\n",
       "      <td>1902.6</td>\n",
       "      <td>300.6</td>\n",
       "      <td>1500.9</td>\n",
       "      <td>101.0</td>\n",
       "      <td>222.1</td>\n",
       "      <td>179.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>29.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>11151</td>\n",
       "      <td>1762</td>\n",
       "      <td>8797</td>\n",
       "      <td>592</td>\n",
       "      <td>1302</td>\n",
       "      <td>1054</td>\n",
       "      <td>16</td>\n",
       "      <td>173</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2016</td>\n",
       "      <td>585501</td>\n",
       "      <td>1957.3</td>\n",
       "      <td>302.5</td>\n",
       "      <td>1518.2</td>\n",
       "      <td>136.6</td>\n",
       "      <td>244.2</td>\n",
       "      <td>195.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>11460</td>\n",
       "      <td>1771</td>\n",
       "      <td>8889</td>\n",
       "      <td>800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1146</td>\n",
       "      <td>20</td>\n",
       "      <td>205</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2017</td>\n",
       "      <td>579315</td>\n",
       "      <td>1830.4</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>134.5</td>\n",
       "      <td>237.5</td>\n",
       "      <td>176.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>45.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>10604</td>\n",
       "      <td>1593</td>\n",
       "      <td>8232</td>\n",
       "      <td>779</td>\n",
       "      <td>1376</td>\n",
       "      <td>1022</td>\n",
       "      <td>15</td>\n",
       "      <td>263</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2018</td>\n",
       "      <td>577737</td>\n",
       "      <td>1785.1</td>\n",
       "      <td>264.0</td>\n",
       "      <td>1375.9</td>\n",
       "      <td>145.2</td>\n",
       "      <td>212.2</td>\n",
       "      <td>150.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>42.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>10313</td>\n",
       "      <td>1525</td>\n",
       "      <td>7949</td>\n",
       "      <td>839</td>\n",
       "      <td>1226</td>\n",
       "      <td>870</td>\n",
       "      <td>13</td>\n",
       "      <td>243</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2019</td>\n",
       "      <td>578759</td>\n",
       "      <td>1571.1</td>\n",
       "      <td>241.2</td>\n",
       "      <td>1206.7</td>\n",
       "      <td>123.2</td>\n",
       "      <td>217.4</td>\n",
       "      <td>147.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>9093</td>\n",
       "      <td>1396</td>\n",
       "      <td>6984</td>\n",
       "      <td>713</td>\n",
       "      <td>1258</td>\n",
       "      <td>854</td>\n",
       "      <td>13</td>\n",
       "      <td>324</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3115 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  year  population  property_all  property_burglary  \\\n",
       "0     Alabama  1960     3266740        1035.4              355.9   \n",
       "1     Alabama  1961     3302000         985.5              339.3   \n",
       "2     Alabama  1962     3358000        1067.0              349.1   \n",
       "3     Alabama  1963     3347000        1150.9              376.9   \n",
       "4     Alabama  1964     3407000        1358.7              466.6   \n",
       "...       ...   ...         ...           ...                ...   \n",
       "3110  Wyoming  2015      586107        1902.6              300.6   \n",
       "3111  Wyoming  2016      585501        1957.3              302.5   \n",
       "3112  Wyoming  2017      579315        1830.4              275.0   \n",
       "3113  Wyoming  2018      577737        1785.1              264.0   \n",
       "3114  Wyoming  2019      578759        1571.1              241.2   \n",
       "\n",
       "      property_larceny  property_motor  violent_all  violent_assault  \\\n",
       "0                592.1            87.3        186.6            138.1   \n",
       "1                569.4            76.8        168.5            128.9   \n",
       "2                634.5            83.4        157.3            119.0   \n",
       "3                683.4            90.6        182.7            142.1   \n",
       "4                784.1           108.0        213.1            163.0   \n",
       "...                ...             ...          ...              ...   \n",
       "3110            1500.9           101.0        222.1            179.8   \n",
       "3111            1518.2           136.6        244.2            195.7   \n",
       "3112            1421.0           134.5        237.5            176.4   \n",
       "3113            1375.9           145.2        212.2            150.6   \n",
       "3114            1206.7           123.2        217.4            147.6   \n",
       "\n",
       "      violent_murder  violent_rape  violent_robbery  totals_property_all  \\\n",
       "0               12.4           8.6             27.5                33823   \n",
       "1               12.9           7.6             19.1                32541   \n",
       "2                9.4           6.5             22.5                35829   \n",
       "3               10.2           5.7             24.7                38521   \n",
       "4                9.3          11.7             29.1                46290   \n",
       "...              ...           ...              ...                  ...   \n",
       "3110             2.7          29.5             10.1                11151   \n",
       "3111             3.4          35.0             10.1                11460   \n",
       "3112             2.6          45.4             13.1                10604   \n",
       "3113             2.3          42.1             17.3                10313   \n",
       "3114             2.2          56.0             11.6                 9093   \n",
       "\n",
       "      totals_property_burglary  totals_property_larceny  \\\n",
       "0                        11626                    19344   \n",
       "1                        11205                    18801   \n",
       "2                        11722                    21306   \n",
       "3                        12614                    22874   \n",
       "4                        15898                    26713   \n",
       "...                        ...                      ...   \n",
       "3110                      1762                     8797   \n",
       "3111                      1771                     8889   \n",
       "3112                      1593                     8232   \n",
       "3113                      1525                     7949   \n",
       "3114                      1396                     6984   \n",
       "\n",
       "      totals_property_motor  totals_violent_all  totals_violent_assault  \\\n",
       "0                      2853                6097                    4512   \n",
       "1                      2535                5564                    4255   \n",
       "2                      2801                5283                    3995   \n",
       "3                      3033                6115                    4755   \n",
       "4                      3679                7260                    5555   \n",
       "...                     ...                 ...                     ...   \n",
       "3110                    592                1302                    1054   \n",
       "3111                    800                1430                    1146   \n",
       "3112                    779                1376                    1022   \n",
       "3113                    839                1226                     870   \n",
       "3114                    713                1258                     854   \n",
       "\n",
       "      totals_violent_murder  totals_violent_rape  totals_violent_robbery  \n",
       "0                       406                  281                     898  \n",
       "1                       427                  252                     630  \n",
       "2                       316                  218                     754  \n",
       "3                       340                  192                     828  \n",
       "4                       316                  397                     992  \n",
       "...                     ...                  ...                     ...  \n",
       "3110                     16                  173                      59  \n",
       "3111                     20                  205                      59  \n",
       "3112                     15                  263                      76  \n",
       "3113                     13                  243                     100  \n",
       "3114                     13                  324                      67  \n",
       "\n",
       "[3115 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n",
    "# Columns that start with \"totals\" are the counts for each state and year\n",
    "# Columns that DON'T start with \"totals\" are the rate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff8d390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.064655Z",
     "iopub.status.busy": "2025-10-23T04:50:10.064111Z",
     "iopub.status.idle": "2025-10-23T04:50:10.078622Z",
     "shell.execute_reply": "2025-10-23T04:50:10.076799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maryland's average violent crime rate: 653.1\n"
     ]
    }
   ],
   "source": [
    "# Here's what we CAN do with filtering:\n",
    "# We can look at one state at a time\n",
    "maryland_crimes = df[df['state'] == 'Maryland']\n",
    "maryland_avg = maryland_crimes['violent_all'].mean()\n",
    "print(f\"Maryland's average violent crime rate: {maryland_avg:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5058c927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.084192Z",
     "iopub.status.busy": "2025-10-23T04:50:10.083643Z",
     "iopub.status.idle": "2025-10-23T04:50:10.095523Z",
     "shell.execute_reply": "2025-10-23T04:50:10.093591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia's average violent crime rate: 279.5\n"
     ]
    }
   ],
   "source": [
    "virginia_crimes = df[df['state'] == 'Virginia']\n",
    "virginia_avg = virginia_crimes['violent_all'].mean()\n",
    "print(f\"Virginia's average violent crime rate: {virginia_avg:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d002110",
   "metadata": {},
   "source": [
    "### The Tedious Alternative\n",
    "\n",
    "Without groupby, to get every state's average, we'd need to:\n",
    "1. Filter for each state individually (50+ times!)\n",
    "2. Calculate the average for each filtered dataset\n",
    "3. Manually combine all the results\n",
    "\n",
    "This would take hundreds of lines of repetitive code. Instead, groupby can do this in a single line! Let's learn how.\n",
    "\n",
    "### A slightly better alternative\n",
    "\n",
    "Let's use a `for` loop to automate this, which will serve as a preview of what Pandas does with the `groupby` function.\n",
    "\n",
    "\n",
    "We will need:\n",
    "- a list of unique states\n",
    "- a for loop which goes through each state\n",
    "- inside the loop, we want to filter to the appropriate state\n",
    "- compute the average violent crime rate for the state\n",
    "- print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "AbzyVHtvyKPS",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.101522Z",
     "iopub.status.busy": "2025-10-23T04:50:10.100785Z",
     "iopub.status.idle": "2025-10-23T04:50:10.153678Z",
     "shell.execute_reply": "2025-10-23T04:50:10.152063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama: 440.5\n",
      "Alaska: 525.1\n",
      "Arizona: 482.7\n",
      "Arkansas: 393.8\n",
      "California: 617.3\n",
      "Colorado: 379.0\n",
      "Connecticut: 290.2\n",
      "Delaware: 477.7\n",
      "District of Columbia: 1594.4\n",
      "Florida: 702.9\n",
      "Georgia: 445.6\n",
      "Hawaii: 219.8\n",
      "Idaho: 208.5\n",
      "Illinois: 606.9\n",
      "Indiana: 325.7\n",
      "Iowa: 207.0\n",
      "Kansas: 327.3\n",
      "Kentucky: 259.3\n",
      "Louisiana: 587.8\n",
      "Maine: 122.6\n",
      "Maryland: 653.1\n",
      "Massachusetts: 435.7\n",
      "Michigan: 552.6\n",
      "Minnesota: 226.7\n",
      "Mississippi: 289.3\n",
      "Missouri: 479.3\n",
      "Montana: 212.4\n",
      "Nebraska: 248.6\n",
      "Nevada: 601.2\n",
      "New Hampshire: 121.9\n",
      "New Jersey: 385.1\n",
      "New Mexico: 596.5\n",
      "New York: 685.3\n",
      "North Carolina: 432.2\n",
      "North Dakota: 103.6\n",
      "Ohio: 339.3\n",
      "Oklahoma: 400.4\n",
      "Oregon: 343.1\n",
      "Pennsylvania: 325.3\n",
      "Rhode Island: 270.5\n",
      "South Carolina: 604.1\n",
      "South Dakota: 179.6\n",
      "Tennessee: 511.3\n",
      "Texas: 472.5\n",
      "United States: 465.7\n",
      "Utah: 221.8\n",
      "Vermont: 109.9\n",
      "Virginia: 279.5\n",
      "Washington: 333.6\n",
      "West Virginia: 200.9\n",
      "Wisconsin: 197.3\n",
      "Wyoming: 221.3\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "unique_states = df['state'].unique()\n",
    "\n",
    "for state in unique_states:\n",
    "    state_data = df[df['state'] == state]\n",
    "    avg_violent = state_data['violent_all'].mean()\n",
    "    print(f\"{state}: {avg_violent:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13defc",
   "metadata": {},
   "source": [
    "## Part 2: The Groupby Mental Model\n",
    "\n",
    "### Understanding \"Split-Apply-Combine\"\n",
    "\n",
    "Groupby works in three steps that we call \"split-apply-combine\":\n",
    "1. **SPLIT** the data into groups (like splitting a deck of cards by suit)\n",
    "2. **APPLY** a calculation to each group (count the cards in each suit)\n",
    "3. **COMBINE** the results back together (report how many of each suit)\n",
    "\n",
    "Let's walk through an example using the image below (from [rostools.org](https://r-cubed-intermediate.rostools.org/sessions/split-apply-combine)):   \n",
    "\n",
    "<img src='https://r-cubed-intermediate.rostools.org/images/split-apply-combine.png' height=500, width=800>\n",
    "\n",
    "Let's see this with a simplified example first, then apply it to our crime data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa7c87f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.157813Z",
     "iopub.status.busy": "2025-10-23T04:50:10.157624Z",
     "iopub.status.idle": "2025-10-23T04:50:10.171053Z",
     "shell.execute_reply": "2025-10-23T04:50:10.169458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mini demonstration dataset:\n",
      "         state  year  violent_all\n",
      "478   Delaware  2018        423.6\n",
      "479   Delaware  2019        422.6\n",
      "1258  Maryland  2018        468.7\n",
      "1259  Maryland  2019        454.1\n",
      "2873  Virginia  2018        200.0\n",
      "2874  Virginia  2019        208.0\n"
     ]
    }
   ],
   "source": [
    "# Create a small example dataset to visualize the concept\n",
    "# Just 3 states, 2 years each\n",
    "demo_df = df[(df['state'].isin(['Maryland', 'Virginia', 'Delaware'])) &\n",
    "             (df['year'].isin([2018, 2019]))]\n",
    "\n",
    "print(\"Our mini demonstration dataset:\")\n",
    "print(demo_df[['state', 'year', 'violent_all']].sort_values(by=['state', 'year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ab9951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.176632Z",
     "iopub.status.busy": "2025-10-23T04:50:10.175876Z",
     "iopub.status.idle": "2025-10-23T04:50:10.183442Z",
     "shell.execute_reply": "2025-10-23T04:50:10.181556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's see the three steps in action:\n",
    "\n",
    "# STEP 1: SPLIT - Python internally separates the data by state\n",
    "# (We don't see this happening, but imagine three separate piles)\n",
    "\n",
    "# STEP 2: APPLY - Calculate mean for each state's pile\n",
    "# Maryland: (454.0 + 453.6) / 2\n",
    "# Virginia: (200.0 + 208.1) / 2\n",
    "# Delaware: (423.6 + 422.6) / 2\n",
    "\n",
    "# STEP 3: COMBINE - Put results into a new structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6etLyAaAz0fj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.189126Z",
     "iopub.status.busy": "2025-10-23T04:50:10.188414Z",
     "iopub.status.idle": "2025-10-23T04:50:10.202191Z",
     "shell.execute_reply": "2025-10-23T04:50:10.200629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average violent crime rate by state (2018-2019):\n",
      "state\n",
      "Delaware    423.1\n",
      "Maryland    461.4\n",
      "Virginia    204.0\n",
      "Name: violent_all, dtype: float64\n",
      "\n",
      "Notice: We got one result per state, not per row!\n"
     ]
    }
   ],
   "source": [
    "avg_violent = demo_df.groupby(by='state')['violent_all'].mean()\n",
    "\n",
    "print(\"Average violent crime rate by state (2018-2019):\")\n",
    "print(avg_violent)\n",
    "print(\"\\nNotice: We got one result per state, not per row!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f5b60",
   "metadata": {},
   "source": [
    "### Quick Check 1\n",
    "\n",
    "Look at the output above. If a state had violent crime rates of 400 in 2018 and 500 in 2019, what would its average be? Think about it before moving on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354d763",
   "metadata": {},
   "source": [
    "## Part 3: Core Groupby Operations\n",
    "\n",
    "### The Essential Methods: size(), mean(), sum(), max(), min()\n",
    "\n",
    "Different methods answer different questions. Let's explore each one using our full dataset, focusing on recent years for cleaner analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbded51c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.207594Z",
     "iopub.status.busy": "2025-10-23T04:50:10.207128Z",
     "iopub.status.idle": "2025-10-23T04:50:10.217478Z",
     "shell.execute_reply": "2025-10-23T04:50:10.215748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 520 records from 2010 onwards\n"
     ]
    }
   ],
   "source": [
    "# Focus on recent decade for most examples\n",
    "recent_df = df[df['year'] >= 2010]\n",
    "print(f\"Working with {len(recent_df)} records from 2010 onwards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad78424a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.223135Z",
     "iopub.status.busy": "2025-10-23T04:50:10.222381Z",
     "iopub.status.idle": "2025-10-23T04:50:10.235038Z",
     "shell.execute_reply": "2025-10-23T04:50:10.233286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records per state:\n",
      "state\n",
      "Alabama       10\n",
      "Alaska        10\n",
      "Arizona       10\n",
      "Arkansas      10\n",
      "California    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# METHOD 1: .size() - How many records in each group?\n",
    "# This counts rows, regardless of what's in them\n",
    "records_per_state = recent_df.groupby(by='state').size()\n",
    "\n",
    "print(\"Number of records per state:\")\n",
    "print(records_per_state.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8877c780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.240377Z",
     "iopub.status.busy": "2025-10-23T04:50:10.239833Z",
     "iopub.status.idle": "2025-10-23T04:50:10.255522Z",
     "shell.execute_reply": "2025-10-23T04:50:10.253623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average property crime rate by state (2010-2019):\n",
      "state\n",
      "District of Columbia    4690.74\n",
      "New Mexico              3592.06\n",
      "South Carolina          3442.40\n",
      "Louisiana               3436.60\n",
      "Washington              3411.28\n",
      "Name: property_all, dtype: float64\n",
      "\n",
      "These states have the highest property crime on average\n"
     ]
    }
   ],
   "source": [
    "# METHOD 2: .mean() - Calculate averages for each group\n",
    "# This is perfect for finding typical crime rates\n",
    "avg_property_by_state = recent_df.groupby(by='state')['property_all'].mean()\n",
    "\n",
    "print(\"Average property crime rate by state (2010-2019):\")\n",
    "print(avg_property_by_state.nlargest(n=5))\n",
    "print(\"\\nThese states have the highest property crime on average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed44eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.260743Z",
     "iopub.status.busy": "2025-10-23T04:50:10.260222Z",
     "iopub.status.idle": "2025-10-23T04:50:10.274275Z",
     "shell.execute_reply": "2025-10-23T04:50:10.272828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total violent crimes by state (2010-2019 combined):\n",
      "state\n",
      "United States    12350037\n",
      "California        1658477\n",
      "Texas             1139761\n",
      "Florida            924962\n",
      "New York           744843\n",
      "Name: totals_violent_all, dtype: int64\n",
      "\n",
      "Note: Larger states have more total crimes (population effect)\n"
     ]
    }
   ],
   "source": [
    "# METHOD 3: .sum() - Add up values in each group\n",
    "# Use this with TOTALS not RATES (rates don't add meaningfully)\n",
    "total_violent_by_state = recent_df.groupby(by='state')['totals_violent_all'].sum()\n",
    "\n",
    "print(\"Total violent crimes by state (2010-2019 combined):\")\n",
    "print(total_violent_by_state.nlargest(n=5))\n",
    "print(\"\\nNote: Larger states have more total crimes (population effect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4632a74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.279222Z",
     "iopub.status.busy": "2025-10-23T04:50:10.278814Z",
     "iopub.status.idle": "2025-10-23T04:50:10.298399Z",
     "shell.execute_reply": "2025-10-23T04:50:10.296952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each state's WORST violent crime rate (2010-2019):\n",
      "state\n",
      "District of Columbia    1326.8\n",
      "Alaska                   885.0\n",
      "New Mexico               856.6\n",
      "Nevada                   695.9\n",
      "Tennessee                651.5\n",
      "Name: violent_all, dtype: float64\n",
      "\n",
      "Each state's BEST violent crime rate (2010-2019):\n",
      "state\n",
      "Vermont           99.3\n",
      "Maine            112.1\n",
      "New Hampshire    152.5\n",
      "Connecticut      183.6\n",
      "Virginia         190.1\n",
      "Name: violent_all, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# METHOD 4: .max() and .min() - Find extremes in each group\n",
    "# Useful for finding best/worst years\n",
    "worst_year_by_state = recent_df.groupby(by='state')['violent_all'].max()\n",
    "best_year_by_state = recent_df.groupby(by='state')['violent_all'].min()\n",
    "\n",
    "print(\"Each state's WORST violent crime rate (2010-2019):\")\n",
    "print(worst_year_by_state.nlargest(n=5))\n",
    "\n",
    "print(\"\\nEach state's BEST violent crime rate (2010-2019):\")\n",
    "print(best_year_by_state.nsmallest(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48684cdc",
   "metadata": {},
   "source": [
    "### Quick Check 2\n",
    "\n",
    "You want to find which states have seen the most murders total over the past decade.\n",
    "Would you use:\n",
    "- `groupby('state')['violent_murder'].sum()`\n",
    "- `groupby('state')['totals_violent_murder'].sum()`\n",
    "\n",
    "Think about the difference between rates and totals!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c69194",
   "metadata": {},
   "source": [
    "## Part 4: The Power of Filter-Then-Group\n",
    "\n",
    "### Combining What You Know\n",
    "\n",
    "One of the most powerful patterns in data analysis is filtering your data first, then grouping. This lets you compare different time periods, crime types, or any other subset.\n",
    "\n",
    "Let's answer a real policy question: \"How has violent crime changed between the 2000s and 2010s?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67d9703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.303636Z",
     "iopub.status.busy": "2025-10-23T04:50:10.303226Z",
     "iopub.status.idle": "2025-10-23T04:50:10.318500Z",
     "shell.execute_reply": "2025-10-23T04:50:10.316794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Alabama       443.56\n",
       "Alaska        621.89\n",
       "Arizona       512.89\n",
       "Arkansas      492.81\n",
       "California    550.07\n",
       "Name: violent_all, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATTERN: Filter for time period, then group by state\n",
    "\n",
    "# First, get crime rates for the 2000s\n",
    "decade_2000s = df[(df['year'] >= 2000) & (df['year'] <= 2009)]\n",
    "crime_2000s = decade_2000s.groupby(by='state')['violent_all'].mean()\n",
    "crime_2000s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1916d872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.324233Z",
     "iopub.status.busy": "2025-10-23T04:50:10.323520Z",
     "iopub.status.idle": "2025-10-23T04:50:10.341020Z",
     "shell.execute_reply": "2025-10-23T04:50:10.339540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Alabama       467.09\n",
       "Alaska        724.03\n",
       "Arizona       439.16\n",
       "Arkansas      515.06\n",
       "California    428.16\n",
       "Name: violent_all, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, get crime rates for the 2010s\n",
    "decade_2010s = df[(df['year'] >= 2010) & (df['year'] <= 2019)]\n",
    "crime_2010s = decade_2010s.groupby(by='state')['violent_all'].mean()\n",
    "crime_2010s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174f67b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.346257Z",
     "iopub.status.busy": "2025-10-23T04:50:10.345796Z",
     "iopub.status.idle": "2025-10-23T04:50:10.353151Z",
     "shell.execute_reply": "2025-10-23T04:50:10.351404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify that the states line up (we'll do this visually right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qPTdtCDI7is6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.358592Z",
     "iopub.status.busy": "2025-10-23T04:50:10.358033Z",
     "iopub.status.idle": "2025-10-23T04:50:10.365727Z",
     "shell.execute_reply": "2025-10-23T04:50:10.364176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate improvement (positive = crime went down)\n",
    "improvement = crime_2000s - crime_2010s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "793132b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.371285Z",
     "iopub.status.busy": "2025-10-23T04:50:10.370574Z",
     "iopub.status.idle": "2025-10-23T04:50:10.382797Z",
     "shell.execute_reply": "2025-10-23T04:50:10.381187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with BIGGEST DECREASE in violent crime (2000s â†’ 2010s):\n",
      "state\n",
      "District of Columbia    299.18\n",
      "Florida                 265.64\n",
      "South Carolina          251.61\n",
      "Maryland                219.69\n",
      "Delaware                155.42\n",
      "Name: violent_all, dtype: float64\n",
      "\n",
      "These states have made the most progress!\n"
     ]
    }
   ],
   "source": [
    "print(\"States with BIGGEST DECREASE in violent crime (2000s â†’ 2010s):\")\n",
    "print(improvement.nlargest(n=5))\n",
    "print(\"\\nThese states have made the most progress!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad5ca271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.388014Z",
     "iopub.status.busy": "2025-10-23T04:50:10.387523Z",
     "iopub.status.idle": "2025-10-23T04:50:10.399360Z",
     "shell.execute_reply": "2025-10-23T04:50:10.397699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States where violent crime INCREASED:\n",
      "state\n",
      "South Dakota    -150.31\n",
      "North Dakota    -117.84\n",
      "Alaska          -102.14\n",
      "Wisconsin        -38.98\n",
      "West Virginia    -38.89\n",
      "New Hampshire    -34.42\n",
      "Indiana          -25.91\n",
      "Alabama          -23.53\n",
      "Vermont          -23.13\n",
      "Arkansas         -22.25\n",
      "Maine             -9.99\n",
      "Hawaii            -0.60\n",
      "Name: violent_all, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Which states got worse?\n",
    "worsened = improvement[improvement < 0].sort_values()\n",
    "\n",
    "if len(worsened) > 0:\n",
    "    print(\"States where violent crime INCREASED:\")\n",
    "    print(worsened)\n",
    "else:\n",
    "    print(\"Good news: No states saw increases in violent crime!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c1e6e",
   "metadata": {},
   "source": [
    "### Quick Check 3\n",
    "\n",
    "How would you find the 5 states with the highest burglary rates specifically in 2019?\n",
    "Write the filter and groupby operations in your head before looking at the solution below.\n",
    "\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "\n",
    "```python\n",
    "# Filter for 2019 first\n",
    "df_2019 = df[df['year'] == 2019]\n",
    "# Then group by state and get the mean (though there's only one 2019 per state)\n",
    "# Or just sort the filtered data directly!\n",
    "top_burglary_2019 = df_2019.nlargest(5, 'property_burglary')[['state', 'property_burglary']]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb791a53",
   "metadata": {},
   "source": [
    "## Part 5: Grouping by Multiple Categories\n",
    "\n",
    "### When One Group Isn't Enough\n",
    "\n",
    "Sometimes we need to group by multiple things at once. For example, to see crime trends over time for each state, we need to group by BOTH state AND year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc044f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.405109Z",
     "iopub.status.busy": "2025-10-23T04:50:10.404567Z",
     "iopub.status.idle": "2025-10-23T04:50:10.425118Z",
     "shell.execute_reply": "2025-10-23T04:50:10.423404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state    year\n",
       "Alabama  2010    3528.0\n",
       "         2011    3605.4\n",
       "         2012    3502.2\n",
       "         2013    3351.3\n",
       "         2014    3177.6\n",
       "                  ...  \n",
       "Wyoming  2015    1902.6\n",
       "         2016    1957.3\n",
       "         2017    1830.4\n",
       "         2018    1785.1\n",
       "         2019    1571.1\n",
       "Name: property_all, Length: 520, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by both state and year to see trends\n",
    "state_year_crime = recent_df.groupby(by=['state', 'year'])['property_all'].mean()\n",
    "state_year_crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eGbSctgeBaDr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.430432Z",
     "iopub.status.busy": "2025-10-23T04:50:10.429827Z",
     "iopub.status.idle": "2025-10-23T04:50:10.440362Z",
     "shell.execute_reply": "2025-10-23T04:50:10.438796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maryland's property crime trend:\n",
      "year\n",
      "2010    2995.5\n",
      "2011    2857.2\n",
      "2012    2753.5\n",
      "2013    2663.5\n",
      "2014    2507.5\n",
      "2015    2315.0\n",
      "2016    2284.5\n",
      "2017    2222.3\n",
      "2018    2033.3\n",
      "2019    1950.2\n",
      "Name: property_all, dtype: float64\n",
      "\n",
      "Notice how crime has generally decreased over the decade!\n"
     ]
    }
   ],
   "source": [
    "# This creates a \"MultiIndex\" - let's look at one state's trend\n",
    "print(\"Maryland's property crime trend:\")\n",
    "print(state_year_crime['Maryland'])\n",
    "print(\"\\nNotice how crime has generally decreased over the decade!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "754fa062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.445703Z",
     "iopub.status.busy": "2025-10-23T04:50:10.445214Z",
     "iopub.status.idle": "2025-10-23T04:50:10.469389Z",
     "shell.execute_reply": "2025-10-23T04:50:10.468101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>violent_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2010</td>\n",
       "      <td>383.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>419.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2012</td>\n",
       "      <td>449.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>430.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2014</td>\n",
       "      <td>427.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>222.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2016</td>\n",
       "      <td>244.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2017</td>\n",
       "      <td>237.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2018</td>\n",
       "      <td>212.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2019</td>\n",
       "      <td>217.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  year  violent_all\n",
       "0    Alabama  2010        383.7\n",
       "1    Alabama  2011        419.8\n",
       "2    Alabama  2012        449.9\n",
       "3    Alabama  2013        430.8\n",
       "4    Alabama  2014        427.4\n",
       "..       ...   ...          ...\n",
       "515  Wyoming  2015        222.1\n",
       "516  Wyoming  2016        244.2\n",
       "517  Wyoming  2017        237.5\n",
       "518  Wyoming  2018        212.2\n",
       "519  Wyoming  2019        217.4\n",
       "\n",
       "[520 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For easier manipulation, we can reset the index to make it a regular DataFrame\n",
    "crime_by_state_year = recent_df.groupby(by=['state', 'year'])['violent_all'].mean().reset_index()\n",
    "crime_by_state_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a8fce10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.474137Z",
     "iopub.status.busy": "2025-10-23T04:50:10.473798Z",
     "iopub.status.idle": "2025-10-23T04:50:10.486116Z",
     "shell.execute_reply": "2025-10-23T04:50:10.484787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 worst state-years for violent crime (2010-2019):\n",
      "                   state  year  violent_all\n",
      "80  District of Columbia  2010       1326.8\n",
      "83  District of Columbia  2013       1300.3\n",
      "85  District of Columbia  2015       1269.1\n",
      "84  District of Columbia  2014       1244.4\n",
      "82  District of Columbia  2012       1243.7\n"
     ]
    }
   ],
   "source": [
    "# Now we can easily find extremes\n",
    "worst_state_years = crime_by_state_year.nlargest(n=5, columns='violent_all')\n",
    "print(\"The 5 worst state-years for violent crime (2010-2019):\")\n",
    "print(worst_state_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6236153f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.490835Z",
     "iopub.status.busy": "2025-10-23T04:50:10.490342Z",
     "iopub.status.idle": "2025-10-23T04:50:10.503649Z",
     "shell.execute_reply": "2025-10-23T04:50:10.502100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 5 best state-years for violent crime (2010-2019):\n",
      "       state  year  violent_all\n",
      "464  Vermont  2014         99.3\n",
      "198    Maine  2018        112.1\n",
      "199    Maine  2019        115.2\n",
      "465  Vermont  2015        118.0\n",
      "197    Maine  2017        121.0\n"
     ]
    }
   ],
   "source": [
    "best_state_years = crime_by_state_year.nsmallest(n=5, columns='violent_all')\n",
    "print(\"\\nThe 5 best state-years for violent crime (2010-2019):\")\n",
    "print(best_state_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121b41f",
   "metadata": {},
   "source": [
    "## Part 7: Hands-On Exercise - Regional Crime Analysis\n",
    "\n",
    "Let's apply everything we've learned to compare crime across different regions of the United States. This is the kind of analysis that informs federal policy and resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81a8975a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.508778Z",
     "iopub.status.busy": "2025-10-23T04:50:10.508391Z",
     "iopub.status.idle": "2025-10-23T04:50:10.526715Z",
     "shell.execute_reply": "2025-10-23T04:50:10.525095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions assigned! First few rows:\n",
      "      state region\n",
      "50  Alabama  South\n",
      "51  Alabama  South\n",
      "52  Alabama  South\n",
      "53  Alabama  South\n",
      "54  Alabama  South\n",
      "55  Alabama  South\n",
      "56  Alabama  South\n",
      "57  Alabama  South\n",
      "58  Alabama  South\n",
      "59  Alabama  South\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3390986/3616744852.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recent_df['region'] = recent_df['state'].apply(assign_region)\n"
     ]
    }
   ],
   "source": [
    "# Define regions (simplified - you could improve these groupings!)\n",
    "northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire',\n",
    "             'Rhode Island', 'Vermont', 'New Jersey', 'New York', 'Pennsylvania']\n",
    "south = ['Delaware', 'Florida', 'Georgia', 'Maryland', 'North Carolina',\n",
    "         'South Carolina', 'Virginia', 'District of Columbia', 'West Virginia',\n",
    "         'Kentucky', 'Tennessee', 'Alabama', 'Mississippi', 'Arkansas',\n",
    "         'Louisiana', 'Oklahoma', 'Texas']\n",
    "midwest = ['Illinois', 'Indiana', 'Michigan', 'Ohio', 'Wisconsin',\n",
    "           'Iowa', 'Kansas', 'Minnesota', 'Missouri', 'Nebraska',\n",
    "           'North Dakota', 'South Dakota']\n",
    "west = ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'New Mexico',\n",
    "        'Utah', 'Wyoming', 'Alaska', 'California', 'Hawaii', 'Oregon', 'Washington']\n",
    "\n",
    "# Function to assign region based on state name\n",
    "def assign_region(state):\n",
    "    if state in northeast:\n",
    "        return 'Northeast'\n",
    "    elif state in south:\n",
    "        return 'South'\n",
    "    elif state in midwest:\n",
    "        return 'Midwest'\n",
    "    elif state in west:\n",
    "        return 'West'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Add region column to our recent data\n",
    "recent_df['region'] = recent_df['state'].apply(assign_region)\n",
    "\n",
    "print(\"Regions assigned! First few rows:\")\n",
    "print(recent_df[['state', 'region']].head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "912283a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.531625Z",
     "iopub.status.busy": "2025-10-23T04:50:10.531227Z",
     "iopub.status.idle": "2025-10-23T04:50:10.544334Z",
     "shell.execute_reply": "2025-10-23T04:50:10.542529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average violent crime rate by region:\n",
      "region\n",
      "South        464.775294\n",
      "Other        386.560000\n",
      "West         386.018462\n",
      "Midwest      338.559167\n",
      "Northeast    255.097778\n",
      "Name: violent_all, dtype: float64\n",
      "\n",
      "Highest: South with 464.8\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Which region has the highest average violent crime rate?\n",
    "# SOLUTION\n",
    "regional_violent = recent_df.groupby(by='region')['violent_all'].mean()\n",
    "\n",
    "print(\"Average violent crime rate by region:\")\n",
    "print(regional_violent.sort_values(ascending=False))\n",
    "print(f\"\\nHighest: {regional_violent.idxmax()} with {regional_violent.max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e71d5c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.549794Z",
     "iopub.status.busy": "2025-10-23T04:50:10.549298Z",
     "iopub.status.idle": "2025-10-23T04:50:10.562486Z",
     "shell.execute_reply": "2025-10-23T04:50:10.560744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average property crime rate by region:\n",
      "region\n",
      "South        2971.304118\n",
      "West         2781.006923\n",
      "Other        2564.660000\n",
      "Midwest      2357.296667\n",
      "Northeast    1848.790000\n",
      "Name: property_all, dtype: float64\n",
      "\n",
      "Highest: South with 2971.3\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: How do property crime rates compare across regions?\n",
    "# SOLUTION\n",
    "regional_property = recent_df.groupby(by='region')['property_all'].mean()\n",
    "\n",
    "print(\"Average property crime rate by region:\")\n",
    "print(regional_property.sort_values(ascending=False))\n",
    "print(f\"\\nHighest: {regional_property.idxmax()} with {regional_property.max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4f39166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.567841Z",
     "iopub.status.busy": "2025-10-23T04:50:10.567302Z",
     "iopub.status.idle": "2025-10-23T04:50:10.585732Z",
     "shell.execute_reply": "2025-10-23T04:50:10.584200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in violent crime by region (2010 to 2019):\n",
      "region\n",
      "Northeast    47.011111\n",
      "South        45.864706\n",
      "Other        25.100000\n",
      "Midwest     -21.716667\n",
      "West        -47.384615\n",
      "Name: violent_all, dtype: float64\n",
      "\n",
      "Biggest decrease: Northeast with 47.0 point reduction\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Which region has seen the biggest decrease from 2010 to 2019?\n",
    "# Hint: Filter for 2010, group by region, then filter for 2019, group by region, then compare\n",
    "\n",
    "# SOLUTION\n",
    "crime_2010 = recent_df[recent_df['year'] == 2010].groupby(by='region')['violent_all'].mean()\n",
    "crime_2019 = recent_df[recent_df['year'] == 2019].groupby(by='region')['violent_all'].mean()\n",
    "regional_change = crime_2010 - crime_2019\n",
    "\n",
    "print(\"Change in violent crime by region (2010 to 2019):\")\n",
    "print(regional_change.sort_values(ascending=False))\n",
    "print(f\"\\nBiggest decrease: {regional_change.idxmax()} with {regional_change.max():.1f} point reduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d89c6b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.591311Z",
     "iopub.status.busy": "2025-10-23T04:50:10.590808Z",
     "iopub.status.idle": "2025-10-23T04:50:10.604436Z",
     "shell.execute_reply": "2025-10-23T04:50:10.602724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 4: Which specific violent crime type varies most by region?\n",
    "# Look at murder, robbery, and assault separately\n",
    "\n",
    "# SOLUTION\n",
    "regional_murder = recent_df.groupby(by='region')['violent_murder'].mean()\n",
    "regional_robbery = recent_df.groupby(by='region')['violent_robbery'].mean()\n",
    "regional_assault = recent_df.groupby(by='region')['violent_assault'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "XKKDQjIwDVRg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.609828Z",
     "iopub.status.busy": "2025-10-23T04:50:10.609326Z",
     "iopub.status.idle": "2025-10-23T04:50:10.617805Z",
     "shell.execute_reply": "2025-10-23T04:50:10.616310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the range (max - min) for each crime type\n",
    "# SOLUTION\n",
    "murder_range = regional_murder.max() - regional_murder.min()\n",
    "robbery_range = regional_robbery.max() - regional_robbery.min()\n",
    "assault_range = regional_assault.max() - regional_assault.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cHFa10vBDSk0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.623021Z",
     "iopub.status.busy": "2025-10-23T04:50:10.622357Z",
     "iopub.status.idle": "2025-10-23T04:50:10.632350Z",
     "shell.execute_reply": "2025-10-23T04:50:10.630531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range by crime type across regions:\n",
      "Murder: 4.2\n",
      "Robbery: 51.0\n",
      "Assault: 146.7\n",
      "\n",
      "Crime type with most regional variation: Assault\n"
     ]
    }
   ],
   "source": [
    "print(f\"Range by crime type across regions:\")\n",
    "print(f\"Murder: {murder_range:.1f}\")\n",
    "print(f\"Robbery: {robbery_range:.1f}\")\n",
    "print(f\"Assault: {assault_range:.1f}\")\n",
    "print(f\"\\nCrime type with most regional variation: {'Murder' if murder_range > max(robbery_range, assault_range) else 'Robbery' if robbery_range > assault_range else 'Assault'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d41f2",
   "metadata": {},
   "source": [
    "## Quick Reference Card\n",
    "\n",
    "### Essential Groupby Patterns\n",
    "\n",
    "```python\n",
    "# BASIC GROUPBY OPERATIONS\n",
    "\n",
    "# Count records in each group\n",
    "df.groupby('column').size()\n",
    "\n",
    "# Average of a column for each group\n",
    "df.groupby('column')['numeric_column'].mean()\n",
    "\n",
    "# Sum totals for each group (use with counts, not rates!)\n",
    "df.groupby('column')['totals_column'].sum()\n",
    "\n",
    "# Find maximum/minimum in each group\n",
    "df.groupby('column')['numeric_column'].max()\n",
    "df.groupby('column')['numeric_column'].min()\n",
    "\n",
    "# FILTER THEN GROUP\n",
    "\n",
    "# First filter your data\n",
    "filtered = df[df['year'] >= 2015]\n",
    "# Then group the filtered data\n",
    "filtered.groupby('state')['column'].mean()\n",
    "\n",
    "# MULTIPLE GROUPING\n",
    "\n",
    "# Group by two or more columns\n",
    "df.groupby(['column1', 'column2']).size()\n",
    "# Reset index to make it easier to work with\n",
    "df.groupby(['column1', 'column2']).mean().reset_index()\n",
    "\n",
    "\n",
    "# TOP N IN EACH GROUP\n",
    "\n",
    "# Find top 5 in each group\n",
    "df.groupby('column')['value'].nlargest(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c0e88",
   "metadata": {},
   "source": [
    "## Summary: Why Groupby Matters\n",
    "\n",
    "Today you learned to:\n",
    "- Use groupby to calculate statistics for each category separately\n",
    "- Apply the \"split-apply-combine\" mental model\n",
    "- Combine filtering with groupby for complex comparisons\n",
    "- Group by multiple columns to find detailed patterns\n",
    "- Use .agg() to get multiple statistics at once\n",
    "\n",
    "These skills let you answer questions like:\n",
    "- Which states have the highest crime rates?\n",
    "- How has crime changed over time?\n",
    "- Which regions show different patterns?\n",
    "- Are certain crimes increasing while others decrease?\n",
    "\n",
    "### Next Class\n",
    "We'll learn to visualize these patterns, turning our groupby results into compelling charts that tell the story of crime in America.\n",
    "\n",
    "### AI Prompting Tips for Groupby\n",
    "\n",
    "When asking AI for help with groupby:\n",
    "\n",
    "```\n",
    "\"I have a DataFrame with columns: state, year, violent_all, totals_violent_all\n",
    "I want to find the average violent crime rate for each state.\n",
    "Should I use groupby with mean() on the rates column or sum() on the totals column?\"\n",
    "```\n",
    "\n",
    "Be specific about:\n",
    "- What columns you have\n",
    "- What you're grouping by\n",
    "- Whether you want averages, totals, counts, etc.\n",
    "- Whether you're working with rates or raw counts\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa49ef6c",
   "metadata": {},
   "source": [
    "## Practice Problems - SOLUTIONS\n",
    "\n",
    "Below are solutions to the practice problems. Remember: You're encouraged to use AI tools to help, especially for concepts we haven't covered in class (like correlation)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i301mzfkokc",
   "metadata": {},
   "source": [
    "### Problem 1: Find the 3 states with the highest murder rates in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66kk24m65y7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.638453Z",
     "iopub.status.busy": "2025-10-23T04:50:10.637912Z",
     "iopub.status.idle": "2025-10-23T04:50:10.654024Z",
     "shell.execute_reply": "2025-10-23T04:50:10.652446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 states with highest murder rates in 2019:\n",
      "                     state  violent_murder\n",
      "539   District of Columbia            23.5\n",
      "1139             Louisiana            11.7\n",
      "1499           Mississippi            11.2\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "# Filter for 2019 first\n",
    "df_2019 = df[df['year'] == 2019]\n",
    "\n",
    "# Sort by murder rate (highest first) and take top 3\n",
    "top_murder_2019 = df_2019.sort_values(by='violent_murder', ascending=False).head(n=3)\n",
    "\n",
    "print(\"Top 3 states with highest murder rates in 2019:\")\n",
    "print(top_murder_2019[['state', 'violent_murder']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t9w35h6rv0g",
   "metadata": {},
   "source": [
    "### Problem 2: Which state has seen the biggest decrease in property crime from 1990 to 2019?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2rm0j0jroe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.659842Z",
     "iopub.status.busy": "2025-10-23T04:50:10.659295Z",
     "iopub.status.idle": "2025-10-23T04:50:10.713611Z",
     "shell.execute_reply": "2025-10-23T04:50:10.712428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State with biggest decrease in property crime (1990-2019):\n",
      "Florida: 5420.8 point decrease\n",
      "From 7566.5 in 1990 to 2145.7 in 2019\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "# Get property crime rates for 1990\n",
    "df_1990 = df[df['year'] == 1990]\n",
    "\n",
    "# Get property crime rates for 2019\n",
    "df_2019 = df[df['year'] == 2019]\n",
    "\n",
    "# For each state, calculate the change\n",
    "# We'll do this by filtering to each state and comparing\n",
    "states = df['state'].unique()\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "for state in states:\n",
    "    rate_1990 = df_1990[df_1990['state'] == state]['property_all'].values\n",
    "    rate_2019 = df_2019[df_2019['state'] == state]['property_all'].values\n",
    "    \n",
    "    # Check if we have data for both years\n",
    "    if len(rate_1990) > 0 and len(rate_2019) > 0:\n",
    "        change = rate_1990[0] - rate_2019[0]\n",
    "        results.append({'state': state, 'change': change, \n",
    "                       'rate_1990': rate_1990[0], 'rate_2019': rate_2019[0]})\n",
    "\n",
    "# Convert to DataFrame and sort by change\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='change', ascending=False)\n",
    "\n",
    "# Get the state with biggest decrease\n",
    "biggest = results_df.head(n=1)\n",
    "\n",
    "print(f\"State with biggest decrease in property crime (1990-2019):\")\n",
    "print(f\"{biggest['state'].values[0]}: {biggest['change'].values[0]:.1f} point decrease\")\n",
    "print(f\"From {biggest['rate_1990'].values[0]:.1f} in 1990 to {biggest['rate_2019'].values[0]:.1f} in 2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cppc5dt0d79",
   "metadata": {},
   "source": [
    "### Problem 3: Calculate the correlation between violent and property crime rates by state\n",
    "\n",
    "**Note**: We didn't cover correlation in class! This is a perfect opportunity to ask an AI tool:\n",
    "- \"What does correlation mean?\"\n",
    "- \"How do I calculate correlation between two columns in pandas?\"\n",
    "- \"What does a correlation of 0.8 mean vs 0.2?\"\n",
    "\n",
    "The AI can explain that correlation measures how two variables move together, ranging from -1 (perfect negative relationship) to +1 (perfect positive relationship)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfu39f9jr9o",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.717968Z",
     "iopub.status.busy": "2025-10-23T04:50:10.717590Z",
     "iopub.status.idle": "2025-10-23T04:50:10.727478Z",
     "shell.execute_reply": "2025-10-23T04:50:10.726146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between violent and property crime rates by state: 0.706\n",
      "\n",
      "Interpretation:\n",
      "Strong positive correlation - states with high violent crime tend to have high property crime\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "# First, get average crime rates by state\n",
    "state_violent = df.groupby('state')['violent_all'].mean()\n",
    "state_property = df.groupby('state')['property_all'].mean()\n",
    "\n",
    "# We haven't covered .corr() yet, so this is where AI tools come in handy!\n",
    "# You could ask: \"How do I calculate correlation between two pandas Series?\"\n",
    "# The AI would tell you about .corr()\n",
    "\n",
    "correlation = state_violent.corr(state_property)\n",
    "\n",
    "print(f\"Correlation between violent and property crime rates by state: {correlation:.3f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "if correlation > 0.7:\n",
    "    print(\"Strong positive correlation - states with high violent crime tend to have high property crime\")\n",
    "elif correlation > 0.3:\n",
    "    print(\"Moderate positive correlation - some relationship between violent and property crime\")\n",
    "else:\n",
    "    print(\"Weak correlation - violent and property crime rates don't move together strongly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wfdczobqs5m",
   "metadata": {},
   "source": [
    "### Problem 4: Find which year had the highest total murders nationwide\n",
    "\n",
    "**Note**: The original problem said \"day\" but our data is yearly, so we'll find the year instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "wthu7q9ygzc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.732935Z",
     "iopub.status.busy": "2025-10-23T04:50:10.732511Z",
     "iopub.status.idle": "2025-10-23T04:50:10.742797Z",
     "shell.execute_reply": "2025-10-23T04:50:10.741328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with highest total murders nationwide: 1991\n",
      "Total murders: 49,406\n",
      "\n",
      "Top 5 worst years:\n",
      "year\n",
      "1991    49406\n",
      "1993    49052\n",
      "1992    47520\n",
      "1990    46876\n",
      "1994    46652\n",
      "Name: totals_violent_murder, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "# Group by year and sum the total murders across all states\n",
    "murders_by_year = df.groupby('year')['totals_violent_murder'].sum()\n",
    "\n",
    "# Find the year with the highest total\n",
    "worst_year = murders_by_year.idxmax()\n",
    "worst_year_total = murders_by_year.max()\n",
    "\n",
    "print(f\"Year with highest total murders nationwide: {worst_year}\")\n",
    "print(f\"Total murders: {worst_year_total:,.0f}\")\n",
    "\n",
    "print(\"\\nTop 5 worst years:\")\n",
    "print(murders_by_year.nlargest(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xhq36rjpm0k",
   "metadata": {},
   "source": [
    "### Problem 5: Which state has the most consistent crime rate (smallest difference between min and max)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "l243pidpf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T04:50:10.747434Z",
     "iopub.status.busy": "2025-10-23T04:50:10.746956Z",
     "iopub.status.idle": "2025-10-23T04:50:10.762859Z",
     "shell.execute_reply": "2025-10-23T04:50:10.761411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State with most consistent violent crime rate: Vermont\n",
      "Range: 192.7 points\n",
      "Min: 9.5, Max: 202.2\n",
      "\n",
      "5 most consistent states:\n",
      "state\n",
      "Vermont          192.7\n",
      "Maine            197.0\n",
      "Virginia         197.2\n",
      "New Hampshire    204.0\n",
      "North Dakota     270.4\n",
      "Name: range, dtype: float64\n",
      "\n",
      "5 most volatile states:\n",
      "state\n",
      "District of Columbia    2368.1\n",
      "Florida                 1052.2\n",
      "Louisiana                926.0\n",
      "South Carolina           906.9\n",
      "California               887.0\n",
      "Name: range, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "# For each state, calculate the range (max - min) of violent crime rates\n",
    "state_stats = df.groupby('state')['violent_all'].agg(['max', 'min'])\n",
    "state_stats['range'] = state_stats['max'] - state_stats['min']\n",
    "\n",
    "# Sort by range to find most consistent (smallest range)\n",
    "state_stats = state_stats.sort_values(by='range')\n",
    "\n",
    "# Get the state with smallest range\n",
    "most_consistent = state_stats.head(n=1)\n",
    "\n",
    "print(f\"State with most consistent violent crime rate: {most_consistent.index[0]}\")\n",
    "print(f\"Range: {most_consistent['range'].values[0]:.1f} points\")\n",
    "print(f\"Min: {most_consistent['min'].values[0]:.1f}, Max: {most_consistent['max'].values[0]:.1f}\")\n",
    "\n",
    "print(\"\\n5 most consistent states:\")\n",
    "print(state_stats.head(n=5)['range'])\n",
    "\n",
    "print(\"\\n5 most volatile states:\")\n",
    "print(state_stats.sort_values(by='range', ascending=False).head(n=5)['range'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
