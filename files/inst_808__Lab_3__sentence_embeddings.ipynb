{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37169ea7-e797-44fc-b2d1-3753f43f0ed0",
   "metadata": {},
   "source": [
    "# Lab 3: Contextualized Embeddings\n",
    "In natural language processing (NLP), words rarely exist in isolation. The meaning of a word often depends heavily on its surrounding context. Traditional word embeddings like Word2Vec and GloVe assign a single vector representation to each word, regardless of context. While useful, this approach has limitations when dealing with polysemous words (words with multiple meanings).\n",
    "\n",
    "This lab explores **contextualized embeddings** that captures how the meaning of words shifts based on their context. Using transformer-based models like DistilBERT, we'll examine how the vector representations of words change when they appear in different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c7c47-98f1-41e1-81e2-c9466cf3c461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Add imports for t-SNE and UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Verify we're using CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a338a-79b4-430e-a8ab-57b412c03c85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install transformers sentence-transformers numpy matplotlib scikit-learn pandas torch seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4bd02-51ca-4ce4-b2d1-a9e57cd414ff",
   "metadata": {},
   "source": [
    "## Part 1: Case Study of Polysemous Words\n",
    "Our case study focuses on two words with multiple meanings: \"space\" and \"ship\". We'll examine sentences where these words are used in different contexts:\n",
    "- Outer space vs. physical space\n",
    "- Spaceships vs. seafaring ships\n",
    "\n",
    "We will use a smaller version of BERT in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc51d0b-d3ab-45bd-9e88-4493cc70d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"distilbert-base-uncased\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69cef2-7197-4afe-a2c0-11985041d840",
   "metadata": {},
   "source": [
    "Not quite grammatically correct but still coherent sentences with \"space\" (outer space vs abstrct physical space)  and \"ship\" (spaceship vs seafaring ship) in different contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e13d3e-414b-4fef-abe6-5b7373d41526",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    \"The space ship 's rockets launched into the atmosphere.\",  \n",
    "    \"The space in the ship 's hull was flooded with water after hitting the reef.\",\n",
    "    \"The cruise ship had plenty of space for guests on the 10th floor.\",\n",
    "    \"Blackholes in space are dangerous for ship s that get close to the event horizon.\",  \n",
    "]\n",
    "\n",
    "# Target words to extract embeddings for\n",
    "target_words = [\"space\", \"ship\"]\n",
    "\n",
    "# Extract embeddings for the target words in isolation (without context)\n",
    "isolated_embeddings = {}\n",
    "for word in target_words:\n",
    "    # Tokenize the word\n",
    "    tokens = tokenizer(word, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "    # Get the embedding from BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        word_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "    isolated_embeddings[word] = word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5881e9-359c-4527-9818-276fdb906f87",
   "metadata": {},
   "source": [
    "### Extract embeddings for these words in different contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198dd268-8476-4c0f-b89a-cb8b18aaa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualized_embeddings = {}\n",
    "\n",
    "for context in contexts:\n",
    "    # Tokenize the sentence\n",
    "    tokenized = tokenizer(context, return_tensors=\"pt\")\n",
    "\n",
    "    # Get token IDs and map them back to tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"][0])\n",
    "\n",
    "    # Get BERT embeddings for the entire sentence\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized)\n",
    "        embeddings = outputs.last_hidden_state[0].numpy()  # Remove batch dimension\n",
    "\n",
    "    # For each target word, find its occurrence in this context and extract its embedding\n",
    "    for target in target_words:\n",
    "        # Find where the target word occurs in the tokenized sequence\n",
    "        # Note: BERT may split words into subwords, so we need to handle that\n",
    "        target_tokens = tokenizer.tokenize(target)\n",
    "\n",
    "        # Look for the target tokens in the sentence tokens\n",
    "        for i in range(len(tokens)):\n",
    "            if i < len(tokens) - len(target_tokens) + 1:\n",
    "                if all(tokens[i+j].replace(\"##\", \"\") == token.replace(\"##\", \"\") \n",
    "                       for j, token in enumerate(target_tokens)):\n",
    "                    # Found the target word, extract its embedding\n",
    "                    # For multi-token words, average the embeddings\n",
    "                    word_embedding = embeddings[i:i+len(target_tokens)].mean(axis=0)\n",
    "\n",
    "                    # Store the embedding with context information\n",
    "                    contextualized_embeddings[f\"{target} in '{context}'\"] = word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe47a3-2f9e-469c-8417-685e7bd21e45",
   "metadata": {},
   "source": [
    "### Compute similarities between all pairs of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8b21b-e42a-471e-b4ce-35562ff885ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = {**isolated_embeddings, **contextualized_embeddings}\n",
    "similarity_matrix = {}\n",
    "\n",
    "for name1, emb1 in all_embeddings.items():\n",
    "    for name2, emb2 in all_embeddings.items():\n",
    "        if name1 != name2:  # Skip self-comparisons\n",
    "            # Calculate cosine similarity\n",
    "            emb2 = np.array(emb2, ndmin=2)\n",
    "            emb1 = np.array(emb1, ndmin=2)\n",
    "            similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "            similarity_matrix[(name1, name2)] = similarity\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda27638-5d98-49fc-8dbb-f25cd7e3acb1",
   "metadata": {},
   "source": [
    "### Plot\n",
    "Plot embeddings using three different dimensionality reduction techniques\n",
    "- PCA\n",
    "- t-SNE\n",
    "- UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70180f-9ffd-408f-81da-7884972f2dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_embeddings = all_embeddings\n",
    "selected_labels = list(all_embeddings.keys())\n",
    "\n",
    "# Project the embeddings to 2D for visualization\n",
    "embeddings_array = np.vstack(list(selected_embeddings.values()))\n",
    "\n",
    "\n",
    "\n",
    "# Function to clean labels for visualization\n",
    "def clean_label(label):\n",
    "    if 'blackhole' in label.lower():\n",
    "        label = label[:6] + ' outer space'\n",
    "    if 'atmospher' in label.lower():\n",
    "        label = label[:6] + ' outer space'\n",
    "    if 'cruise ship' in label.lower():\n",
    "        label = label[:6] + ' inner space'\n",
    "    if 'hull' in label.lower():\n",
    "        label = label[:6] + ' inner space'\n",
    "    return label\n",
    "\n",
    "# Function to plot embeddings with consistent formatting\n",
    "def plot_embeddings(embeddings_2d, labels, title, method_name):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange', 'brown', 'pink', 'gray']\n",
    "    markers = ['o', 's', '^', 'D', 'x']\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        color = colors[i % len(colors)]\n",
    "        marker = markers[i % len(markers)]\n",
    "        clean_lbl = clean_label(label)\n",
    "        \n",
    "        plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], \n",
    "                   color=color, s=100, marker=marker, label=clean_lbl)\n",
    "        \n",
    "        # Add labels to the points\n",
    "        plt.annotate(clean_lbl, \n",
    "                    (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                    xytext=(5, 5),\n",
    "                     textcoords='offset points',\n",
    "                    fontsize=10)\n",
    "    \n",
    "    plt.title(f'{title} ({method_name})')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 1. PCA Visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pca.fit_transform(embeddings_array)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"PCA explained variance: {explained_variance.sum()*100:.2f}%\")\n",
    "plot_embeddings(pca_embeddings, selected_labels, \n",
    "                'Contextualized Embeddings of \"space\" and \"ship\" in Different Contexts', \n",
    "                f'PCA - Explained Variance: {explained_variance.sum()*100:.2f}%')\n",
    "\n",
    "# 2. t-SNE Visualization\n",
    "# t-SNE is more computationally intensive but often better at preserving local structure\n",
    "tsne = TSNE(n_components=2, perplexity=5, random_state=42, n_iter=1000)\n",
    "tsne_embeddings = tsne.fit_transform(embeddings_array)\n",
    "plot_embeddings(tsne_embeddings, selected_labels, \n",
    "                'Contextualized Embeddings of \"space\" and \"ship\" in Different Contexts', \n",
    "                't-SNE')\n",
    "\n",
    "# 3. UMAP Visualization\n",
    "# UMAP often preserves more global structure than t-SNE while still highlighting local relationships\n",
    "umap_reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, n_components=2, random_state=42)\n",
    "umap_embeddings = umap_reducer.fit_transform(embeddings_array)\n",
    "plot_embeddings(umap_embeddings, selected_labels, \n",
    "                'Contextualized Embeddings of \"space\" and \"ship\" in Different Contexts', \n",
    "                'UMAP')\n",
    "\n",
    "# 4. Bonus: Combined visualization with subplots\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# PCA plot\n",
    "plt.subplot(1, 3, 1)\n",
    "for i, label in enumerate(selected_labels):\n",
    "    color = colors[i % len(colors)]\n",
    "    marker = markers[i % len(markers)]\n",
    "    clean_lbl = clean_label(label)\n",
    "    \n",
    "    plt.scatter(pca_embeddings[i, 0], pca_embeddings[i, 1], \n",
    "               color=color, s=100, marker=marker)\n",
    "    \n",
    "plt.title(f'PCA ({explained_variance.sum()*100:.2f}%)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# t-SNE plot\n",
    "plt.subplot(1, 3, 2)\n",
    "for i, label in enumerate(selected_labels):\n",
    "    color = colors[i % len(colors)]\n",
    "    marker = markers[i % len(markers)]\n",
    "    clean_lbl = clean_label(label)\n",
    "    \n",
    "    plt.scatter(tsne_embeddings[i, 0], tsne_embeddings[i, 1], \n",
    "               color=color, s=100, marker=marker)\n",
    "    \n",
    "plt.title('t-SNE')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# UMAP plot\n",
    "plt.subplot(1, 3, 3)\n",
    "for i, label in enumerate(selected_labels):\n",
    "    color = colors[i % len(colors)]\n",
    "    marker = markers[i % len(markers)]\n",
    "    clean_lbl = clean_label(label)\n",
    "    \n",
    "    plt.scatter(umap_embeddings[i, 0], umap_embeddings[i, 1], \n",
    "               color=color, s=100, marker=marker, label=clean_lbl)\n",
    "    \n",
    "plt.title('UMAP')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a shared legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.figlegend(handles, labels, loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "plt.suptitle('Comparison of Dimensionality Reduction Techniques', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c07d1-5923-4a1c-86d0-2eb312ac8a35",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Exercise 1: Exploring Word Meanings with \"Bank\"\n",
    "\n",
    "In this exercise, you'll explore how contextualized embeddings capture different meanings of the word \"bank\".\n",
    "\n",
    "**Tasks:**\n",
    "1. Use the following sentences containing the word \"bank\":\n",
    "   - \"I need to go to the bank to deposit my paycheck.\"\n",
    "   - \"The river bank was muddy after the heavy rain.\"\n",
    "   - \"The pilot had to bank the airplane to make the turn.\"\n",
    "   - \"You can bank on me to help you move this weekend.\"\n",
    "\n",
    "2. Follow the same steps we used in the \"space/ship\" example:\n",
    "   - Generate contextualized embeddings for \"bank\" in each sentence\n",
    "   - Calculate the cosine similarity between the different embeddings\n",
    "   - Create a visualization using PCA\n",
    "   \n",
    "3. Answer these questions:\n",
    "   - Which pairs of meanings are most similar/different?\n",
    "   - Does the model clearly separate the financial meaning from the other meanings?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146e8f1-4c36-4210-9630-9b6965f8b7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b1d6591-ac22-42aa-8304-4f3aceb015d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 2: Simple Sentiment Analysis\n",
    "This exercise examines how context affects words with positive or negative connotations.\n",
    "\n",
    "**Tasks:**\n",
    "1. Use the word \"bright\" in these contexts:\n",
    "   - \"The future looks bright for our company.\"\n",
    "   - \"She is the brightest student in the class.\"\n",
    "   - \"The room is too bright; can you dim the lights?\"\n",
    "   - \"His bright yellow shirt stood out in the crowd.\"\n",
    "\n",
    "2. Generate contextualized embeddings for \"bright\" in each sentence\n",
    "\n",
    "3. Now use the word \"dark\" in these contexts:\n",
    "   - \"The future looks dark for our company.\"\n",
    "   - \"She has a dark sense of humor.\"\n",
    "   - \"The room is too dark; can you turn on the lights?\"\n",
    "   - \"His dark blue shirt looked professional.\"\n",
    "\n",
    "4. Generate contextualized embeddings for \"dark\" in each sentence\n",
    "\n",
    "5. Visualize all embeddings in a single plot\n",
    "\n",
    "6. Answer these questions:\n",
    "   - Do the embeddings cluster by sentiment (positive/negative) or by meaning (light/intelligence)?\n",
    "   - How does context change the sentiment of these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c383b-9820-4ff9-9139-6ab116911bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad76f47c-694b-4ca3-bc55-9b686c9cc3d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2: Comparing Sentence Embeddings\n",
    "So far, we've explored how contextual word embeddings can capture different meanings of individual words based on their surrounding context. Now we'll take a step further and examine **sentence-level embeddings** - vector representations of entire sentences.\n",
    "\n",
    "### Word-Level vs. Sentence-Level Embeddings\n",
    "\n",
    "There are two main approaches to generating sentence embeddings:\n",
    "\n",
    "1. **Word-level encoders with pooling**: Using models like DistilBERT to get contextualized embeddings for each word in a sentence, then pooling these embeddings (typically by averaging) to create a single vector for the entire sentence.\n",
    "\n",
    "2. **Dedicated sentence encoders**: Using models specifically designed to encode entire sentences directly into fixed-length vectors, such as Sentence-BERT or the SentenceTransformer models.\n",
    "\n",
    "While both approaches generate vector representations of sentences, they differ in how they're trained and optimized. Word-level encoders with pooling leverage the contextual understanding of transformer models, while dedicated sentence encoders are specifically fine-tuned on tasks requiring sentence similarity comparisons.\n",
    "\n",
    "### Why Compare These Approaches?\n",
    "\n",
    "Comparing these approaches helps us understand:\n",
    "\n",
    "- Which embedding method better captures semantic meaning at the sentence level\n",
    "- How dimensionality affects the quality of embeddings (word-level embeddings tend to have higher dimensionality)\n",
    "- Which approach is more effective for downstream tasks like document classification\n",
    "\n",
    "### Experimental Setup\n",
    "\n",
    "In this section, we'll:\n",
    "\n",
    "1. Use a subset of the 20 Newsgroups dataset containing articles from four categories: alt.atheism, comp.graphics, rec.sport.baseball, and sci.med\n",
    "2. Generate sentence embeddings using both approaches\n",
    "3. Compare their effectiveness\n",
    "4. Evaluate their performance on a topic classification task\n",
    "5. Visualize the embedding spaces to understand their structural differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77f6c6-1b7c-4c5d-a7b4-a43224e0fbf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load a news dataset for topic classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26212e4-353f-40ae-b30b-5d50507fedc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_ag_news():\n",
    "    from sklearn.datasets import fetch_20newsgroups\n",
    "    \n",
    "    categories = ['alt.atheism', 'comp.graphics', 'rec.sport.baseball', 'sci.med']\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, \n",
    "                                          remove=('headers', 'footers', 'quotes'))\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, \n",
    "                                         remove=('headers', 'footers', 'quotes'))\n",
    "    \n",
    "    # Combine data and labels\n",
    "    texts_train = newsgroups_train.data\n",
    "    labels_train = newsgroups_train.target\n",
    "    \n",
    "    texts_test = newsgroups_test.data\n",
    "    labels_test = newsgroups_test.target\n",
    "    \n",
    "    # Limit to a smaller subset for faster processing\n",
    "    max_samples = 1000  # Adjust based on computational resources\n",
    "    \n",
    "    if len(texts_train) > max_samples:\n",
    "        indices = np.random.choice(len(texts_train), max_samples, replace=False)\n",
    "        texts_train = [texts_train[i] for i in indices]\n",
    "        labels_train = [labels_train[i] for i in indices]\n",
    "    \n",
    "    if len(texts_test) > max_samples // 4:\n",
    "        indices = np.random.choice(len(texts_test), max_samples // 2, replace=False)\n",
    "        texts_test = [texts_test[i] for i in indices]\n",
    "        labels_test = [labels_test[i] for i in indices]\n",
    "    \n",
    "    # Clean the text data\n",
    "    texts_train = [text[:1000].strip() for text in texts_train]  # Truncate long texts\n",
    "    texts_test = [text[:1000].strip() for text in texts_test]\n",
    "    \n",
    "    # Map numerical labels to category names\n",
    "    label_names = newsgroups_train.target_names\n",
    "    \n",
    "    return (texts_train, labels_train, texts_test, labels_test, label_names)\n",
    "\n",
    "# Load the dataset\n",
    "texts_train, labels_train, texts_test, labels_test, label_names = load_ag_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8917f-8d39-4ae6-81bd-f996f2c33b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Training set: {len(texts_train)} samples\")\n",
    "print(f\"Test set: {len(texts_test)} samples\")\n",
    "print(f\"Topics: {label_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986f9b7-1262-4586-bd0e-7bda2fb51c5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Word-level encoder with mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cb5cd-54c3-47a1-a382-8b70ec62a1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_word_encoder_embeddings(texts, model_name=\"distilbert-base-uncased\"):\n",
    "    \"\"\"Generate embeddings using a word-level encoder with mean pooling.\"\"\"\n",
    "    print(f\"Loading word-level encoder: {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Function for mean pooling\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]  # First element contains token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    batch_size = 32\n",
    "    all_embeddings = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoded_input = tokenizer(batch_texts, padding=True, truncation=True, \n",
    "                                 max_length=512, return_tensors='pt')\n",
    "        \n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "        \n",
    "        # Apply mean pooling\n",
    "        batch_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    # Concatenate all embeddings\n",
    "    embeddings = torch.cat(all_embeddings).numpy()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Generated {len(embeddings)} embeddings with dimension {embeddings.shape[1]}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cef523-3460-4b94-94bf-44869b1ec5a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Now for the sentence encoder approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be3f84-7387-4633-b8b3-341201a0ef3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sentence_encoder_embeddings(texts, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    \"\"\"Generate embeddings using a dedicated sentence encoder.\"\"\"\n",
    "    print(f\"\\nLoading sentence encoder: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Process texts\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # SentenceTransformer handles batching internally\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Generated {len(embeddings)} embeddings with dimension {embeddings.shape[1]}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb5f13-7127-432d-bae4-4a49508ce581",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate embeddings for train and test sets using both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20711f7d-1a9d-4dcf-8aff-bfe27d70a91c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Generating word-level encoder embeddings for training set...\")\n",
    "word_embeddings_train = get_word_encoder_embeddings(texts_train)\n",
    "\n",
    "print(\"Generating word-level encoder embeddings for test set...\")\n",
    "word_embeddings_test = get_word_encoder_embeddings(texts_test)\n",
    "\n",
    "print(\"Generating sentence encoder embeddings for training set...\")\n",
    "sentence_embeddings_train = get_sentence_encoder_embeddings(texts_train)\n",
    "\n",
    "print(\"Generating sentence encoder embeddings for test set...\")\n",
    "sentence_embeddings_test = get_sentence_encoder_embeddings(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250cde5-ff77-4f0d-b0ca-924a1743df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embedding dimensions\n",
    "print(\"\\nEmbedding Comparison:\")\n",
    "print(f\"Word-level embeddings dimension: {word_embeddings_train.shape[1]}\")\n",
    "print(f\"Sentence-level embeddings dimension: {sentence_embeddings_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24737b-3114-4950-b5e8-4658c453e420",
   "metadata": {},
   "source": [
    "### Evaluating embedding quality via topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c001e2-17f4-402e-969b-1e1659e0c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate embeddings using a classifier\n",
    "def evaluate_embeddings(train_embeddings, train_labels, test_embeddings, test_labels, \n",
    "                        embedding_type, label_names):\n",
    "    \"\"\"Evaluate embeddings on topic classification task using logistic regression.\"\"\"\n",
    "    print(f\"\\n--- Evaluating {embedding_type} embeddings ---\")\n",
    "    \n",
    "    # Train a logistic regression classifier\n",
    "    classifier = LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    classifier.fit(train_embeddings, train_labels)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    start_time = time.time()\n",
    "    predictions = classifier.predict(test_embeddings)\n",
    "    predict_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(test_labels, predictions, target_names=label_names)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_labels, predictions)\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"report\": report,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"train_time\": train_time,\n",
    "        \"predict_time\": predict_time\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training time: {train_time:.2f} seconds\")\n",
    "    print(f\"Prediction time: {predict_time:.2f} seconds\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472ae42-b49b-43e7-90bb-fdc4606f363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both embedding types\n",
    "word_results = evaluate_embeddings(\n",
    "    word_embeddings_train, labels_train,\n",
    "    word_embeddings_test, labels_test,\n",
    "    \"Word-level\", label_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ef5fd-d492-4ad5-98fe-53587166c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_results = evaluate_embeddings(\n",
    "    sentence_embeddings_train, labels_train,\n",
    "    sentence_embeddings_test, labels_test,\n",
    "    \"Sentence-level\", label_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d13a336-7701-48b2-b81f-a1e43e3d4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def plot_confusion_matrices(word_cm, sentence_cm, label_names):\n",
    "    \"\"\"Plot confusion matrices for both embedding types.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    # Word embeddings confusion matrix\n",
    "    sns.heatmap(word_cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names,\n",
    "                yticklabels=label_names, ax=axes[0])\n",
    "    axes[0].set_title('Word-level Encoder Confusion Matrix')\n",
    "    axes[0].set_ylabel('True Label')\n",
    "    axes[0].set_xlabel('Predicted Label')\n",
    "    \n",
    "    # Sentence embeddings confusion matrix\n",
    "    sns.heatmap(sentence_cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names,\n",
    "                yticklabels=label_names, ax=axes[1])\n",
    "    axes[1].set_title('Sentence Encoder Confusion Matrix')\n",
    "    axes[1].set_ylabel('True Label')\n",
    "    axes[1].set_xlabel('Predicted Label')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize confusion matrices\n",
    "plot_confusion_matrices(\n",
    "    word_results[\"confusion_matrix\"],\n",
    "    sentence_results[\"confusion_matrix\"],\n",
    "    label_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739077a7-5aac-4476-93d2-db18cc03db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embedding spaces with t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_embeddings(embeddings, labels, label_names, title):\n",
    "    \"\"\"Visualize embeddings using t-SNE dimensionality reduction.\"\"\"\n",
    "    # Sample a subset if there are too many points\n",
    "    if len(embeddings) > 500:\n",
    "        indices = np.random.choice(len(embeddings), 500, replace=False)\n",
    "        sample_embeddings = embeddings[indices]\n",
    "        sample_labels = [labels[i] for i in indices]\n",
    "    else:\n",
    "        sample_embeddings = embeddings\n",
    "        sample_labels = labels\n",
    "    \n",
    "    # Apply t-SNE\n",
    "    print(f\"Applying t-SNE to {title} embeddings...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_embeddings = tsne.fit_transform(sample_embeddings)\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, label in enumerate(np.unique(sample_labels)):\n",
    "        mask = np.array(sample_labels) == label\n",
    "        plt.scatter(reduced_embeddings[mask, 0], reduced_embeddings[mask, 1], \n",
    "                    label=label_names[label], alpha=0.7)\n",
    "    \n",
    "    plt.title(f't-SNE Visualization of {title} Embeddings')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return reduced_embeddings\n",
    "\n",
    "# Visualize both embedding types\n",
    "wl = visualize_embeddings(word_embeddings_train, labels_train, label_names, \"Word-level\")\n",
    "sl = visualize_embeddings(sentence_embeddings_train, labels_train, label_names, \"Sentence-level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26079e92-2397-4b66-8a41-281da8024627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_test = pd.DataFrame([\n",
    "    texts_test,\n",
    "    wl[:, 0],\n",
    "    wl[:, 1],\n",
    "    sl[:, 0],\n",
    "    sl[:, 1],\n",
    "    labels_test]).T\n",
    "\n",
    "df_texts_test.columns = ['text', 'wl0', 'wl1', 'sl0', 'sl1', 'y']\n",
    "\n",
    "ln = pd.DataFrame([[0, 1, 2, 3], label_names]).T\n",
    "ln.columns = ['y', 'topics']\n",
    "\n",
    "df_texts_test = df_texts_test.merge(ln, on=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d107e47-bb85-456c-8709-44f2649c2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_test[(df_texts_test.sl0.between(12, 20)) & (df_texts_test.sl1.between(-13, -5)) & (df_texts_test.topics.str.contains('athe'))].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f2174-64f6-457e-9915-2ab9bb82806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_test[(df_texts_test.sl0.between(12, 20)) & (df_texts_test.sl1.between(-13, -5)) & (df_texts_test.topics.str.contains('spor'))].text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e179e9-bbb4-4161-aa21-0955f6d5494b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cross-model embeddings analysis with topic coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174a02f-04c0-48cb-93c3-87fe018f00ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embedding_space_comparison(word_embeddings, sentence_embeddings, labels, label_names):\n",
    "    \"\"\"Compare the structure of the embedding spaces with topic-based coloring.\"\"\"\n",
    "    from scipy.stats import pearsonr\n",
    "    \n",
    "    print(\"\\n--- Comparing Embedding Spaces ---\")\n",
    "    \n",
    "    \n",
    "    # Sample a subset for computational efficiency if needed\n",
    "    sample_size = min(len(word_embeddings), 200)\n",
    "    indices = np.random.choice(len(word_embeddings), sample_size, replace=False)\n",
    "    \n",
    "    word_samples = word_embeddings[indices]\n",
    "    sentence_samples = sentence_embeddings[indices]\n",
    "    sample_labels = [labels[i] for i in indices]\n",
    "    \n",
    "    # Calculate similarity matrices\n",
    "    word_sim = cosine_similarity(word_samples)\n",
    "    sentence_sim = cosine_similarity(sentence_samples)\n",
    "    \n",
    "    # Create a mapping of indices to topic labels\n",
    "    idx_to_label = {i: sample_labels[i] for i in range(len(sample_labels))}\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    comparison_data = []\n",
    "    \n",
    "    # Flatten the matrices and collect topic information\n",
    "    n = word_sim.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):  # Upper triangular part (excluding diagonal)\n",
    "            # Get the topic pair being compared\n",
    "            topic_i = label_names[idx_to_label[i]]\n",
    "            topic_j = label_names[idx_to_label[j]]\n",
    "            topic_pair = f\"{topic_i}-{topic_j}\"\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'word_sim': word_sim[i, j],\n",
    "                'sentence_sim': sentence_sim[i, j],\n",
    "                'topic_i': topic_i,\n",
    "                'topic_j': topic_j,\n",
    "                'same_topic': topic_i == topic_j\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame for easier handling\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Calculate correlation between similarity matrices\n",
    "    correlation, p_value = pearsonr(df['word_sim'], df['sentence_sim'])\n",
    "    \n",
    "    print(f\"Correlation between similarity structures: {correlation:.4f} (p={p_value:.4e})\")\n",
    "    \n",
    "    # Plot similarity comparison with topic coloring\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create a categorical color map for topic pairs\n",
    "    unique_topics = label_names\n",
    "    unique_topic_pairs = []\n",
    "    \n",
    "    # Create color map for same-topic vs. cross-topic comparisons\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    \n",
    "    # Plot points colored by whether they're comparing same topic or different topics\n",
    "    for same_topic in [True, False]:\n",
    "        subset = df[df['same_topic'] == same_topic]\n",
    "        label = 'Same Topic' if same_topic else 'Different Topics'\n",
    "        color = 'darkblue' if same_topic else 'lightblue'\n",
    "        alpha = 0.7 if same_topic else 0.3\n",
    "        \n",
    "        plt.scatter(subset['word_sim'], subset['sentence_sim'], \n",
    "                   alpha=alpha, c=color, label=label)\n",
    "    \n",
    "    # Create small plots for each topic-topic comparison\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    # Add trend line\n",
    "    from scipy.stats import linregress\n",
    "    slope, intercept, r, p, stderr = linregress(df['word_sim'], df['sentence_sim'])\n",
    "    x = np.array([min(df['word_sim']), max(df['word_sim'])])\n",
    "    y = slope * x + intercept\n",
    "    plt.plot(x, y, color='red', linestyle='--', label=f'Trend (r={correlation:.2f})')\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Word Embedding Cosine Similarity')\n",
    "    plt.ylabel('Sentence Embedding Cosine Similarity')\n",
    "    plt.title('Comparison of Similarity Structures')\n",
    "    \n",
    "    # Legend with two parts: same/different topics and topic pairs\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    # Add a diagonal line for reference\n",
    "    plt.plot([min(df['word_sim']), max(df['word_sim'])], \n",
    "             [min(df['word_sim']), max(df['word_sim'])], \n",
    "             'k--', alpha=0.3, label='Perfect Correlation')\n",
    "    \n",
    "    # Create a second smaller figure for topic-specific patterns\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot separate scatter plots for each topic\n",
    "    for i, topic in enumerate(unique_topics):\n",
    "        plt.subplot(2, len(unique_topics)//2 + len(unique_topics)%2, i+1)\n",
    "        \n",
    "        # Get pairs where either topic is the current one\n",
    "        topic_df = df[(df['topic_i'] == topic) | (df['topic_j'] == topic)]\n",
    "        \n",
    "        # Color by whether both documents are from the same topic\n",
    "        same = topic_df[topic_df['same_topic']]\n",
    "        diff = topic_df[~topic_df['same_topic']]\n",
    "        \n",
    "        if len(same) > 0:\n",
    "            plt.scatter(same['word_sim'], same['sentence_sim'], \n",
    "                       color='darkblue', alpha=0.7, label='Same Topic')\n",
    "        \n",
    "        if len(diff) > 0:\n",
    "            plt.scatter(diff['word_sim'], diff['sentence_sim'],\n",
    "                      color='lightblue', alpha=0.3, label='Different Topic')\n",
    "        \n",
    "        plt.title(f'Topic: {topic}')\n",
    "        plt.xlabel('Word Sim' if i >= len(unique_topics)//2 else '')\n",
    "        plt.ylabel('Sentence Sim' if i % (len(unique_topics)//2 + len(unique_topics)%2) == 0 else '')\n",
    "        \n",
    "        # Add trend line\n",
    "        if len(topic_df) > 2:  # Need at least 3 points for a reasonable trend\n",
    "            slope, intercept, r, p, stderr = linregress(topic_df['word_sim'], topic_df['sentence_sim'])\n",
    "            x = np.array([min(topic_df['word_sim']), max(topic_df['word_sim'])])\n",
    "            y = slope * x + intercept\n",
    "            plt.plot(x, y, color='red', linestyle='--', label=f'r={r:.2f}')\n",
    "        \n",
    "        if i == 0:  # Only add legend to the first subplot\n",
    "            plt.legend(fontsize='small')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Topic-Specific Similarity Comparisons', y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze topic-based similarity patterns\n",
    "    print(\"\\nTopic-Specific Similarity Analysis:\")\n",
    "    for topic in unique_topics:\n",
    "        # Get pairs where both documents are from this topic\n",
    "        topic_pairs = df[(df['topic_i'] == topic) & (df['topic_j'] == topic)]\n",
    "        if len(topic_pairs) > 0:\n",
    "            word_mean = topic_pairs['word_sim'].mean()\n",
    "            sent_mean = topic_pairs['sentence_sim'].mean()\n",
    "            print(f\"Topic '{topic}': Avg Word Sim = {word_mean:.3f}, Avg Sentence Sim = {sent_mean:.3f}\")\n",
    "    \n",
    "    return correlation, p_value, df\n",
    "\n",
    "# Compare embedding spaces with topic coloring\n",
    "correlation, p_value, comparison_df = embedding_space_comparison(\n",
    "    word_embeddings_train, sentence_embeddings_train, labels_train, label_names\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
