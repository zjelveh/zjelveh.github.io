{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INST414 — Lab 4: Performance Metrics + Naive Bayes (with Pandas)\n",
    "\n",
    "**How this notebook works:**\n",
    "- Everything **before** the **Lab Tasks** section is your **pre-lab** work to complete at home.\n",
    "- In class, we’ll focus on the **Lab Tasks** and I’ll call on people to walk through solutions.\n",
    "\n",
    "**Today’s goal:** compute performance metrics as **conditional probabilities**, see how metrics change when you change the **threshold**, and then use **Naive Bayes** to make a simple classification.\n",
    "\n",
    "## Learning goals\n",
    "By the end, you should be able to:\n",
    "- Turn predicted probabilities into predictions using a threshold.\n",
    "- Explain the confusion-matrix cells (TP, FP, TN, FN).\n",
    "- Compute a joint distribution of `( y , \\hat{y} )` with `value_counts`.\n",
    "- Compute **TPR (recall)** and **PPV (precision)** from data.\n",
    "- Use `sort_values`, `between`, and `map` for common data tasks.\n",
    "- Compare two Naive Bayes scores and classify.\n",
    "\n",
    "## How to work in this notebook\n",
    "- Run cells top-to-bottom. If something errors, re-run from the last successful cell.\n",
    "- When you see **Checkpoint** prompts, pause and try before scrolling.\n",
    "- After any big step, do a quick check with `.shape`, `.head()`, and `value_counts()`.\n",
    "\n",
    "## Common issues (quick fixes)\n",
    "- If you get a `KeyError`, check column names with `lab4_data.columns`.\n",
    "- If your probabilities look weird, double-check the denominator (what you’re conditioning on).\n",
    "- If `value_counts` output is hard to read, use `.sort_index()` to organize it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v7ti5o2s13",
   "source": [
    "*",
    "*",
    "B",
    "e",
    "f",
    "o",
    "r",
    "e",
    " ",
    "y",
    "o",
    "u",
    " ",
    "s",
    "t",
    "a",
    "r",
    "t",
    ":",
    "*",
    "*",
    " ",
    "C",
    "l",
    "i",
    "c",
    "k",
    " ",
    "*",
    "*",
    "F",
    "i",
    "l",
    "e",
    " ",
    "→",
    " ",
    "S",
    "a",
    "v",
    "e",
    " ",
    "a",
    " ",
    "c",
    "o",
    "p",
    "y",
    " ",
    "i",
    "n",
    " ",
    "D",
    "r",
    "i",
    "v",
    "e",
    "*",
    "*",
    " ",
    "s",
    "o",
    " ",
    "y",
    "o",
    "u",
    " ",
    "h",
    "a",
    "v",
    "e",
    " ",
    "y",
    "o",
    "u",
    "r",
    " ",
    "o",
    "w",
    "n",
    " ",
    "v",
    "e",
    "r",
    "s",
    "i",
    "o",
    "n",
    " ",
    "o",
    "f",
    " ",
    "t",
    "h",
    "i",
    "s",
    " ",
    "n",
    "o",
    "t",
    "e",
    "b",
    "o",
    "o",
    "k",
    ".",
    " ",
    "I",
    "f",
    " ",
    "y",
    "o",
    "u",
    " ",
    "s",
    "k",
    "i",
    "p",
    " ",
    "t",
    "h",
    "i",
    "s",
    " ",
    "s",
    "t",
    "e",
    "p",
    ",",
    " ",
    "y",
    "o",
    "u",
    "r",
    " ",
    "w",
    "o",
    "r",
    "k",
    " ",
    "w",
    "i",
    "l",
    "l",
    " ",
    "n",
    "o",
    "t",
    " ",
    "b",
    "e",
    " ",
    "s",
    "a",
    "v",
    "e",
    "d",
    ".",
    "\n",
    "\n",
    "*",
    "*",
    "T",
    "u",
    "r",
    "n",
    " ",
    "o",
    "f",
    "f",
    " ",
    "A",
    "I",
    " ",
    "a",
    "s",
    "s",
    "i",
    "s",
    "t",
    "a",
    "n",
    "c",
    "e",
    ":",
    "*",
    "*",
    " ",
    "G",
    "o",
    " ",
    "t",
    "o",
    " ",
    "*",
    "*",
    "S",
    "e",
    "t",
    "t",
    "i",
    "n",
    "g",
    "s",
    " ",
    "→",
    " ",
    "A",
    "I",
    " ",
    "A",
    "s",
    "s",
    "i",
    "s",
    "t",
    "a",
    "n",
    "c",
    "e",
    "*",
    "*",
    " ",
    "a",
    "n",
    "d",
    " ",
    "u",
    "n",
    "c",
    "h",
    "e",
    "c",
    "k",
    " ",
    "e",
    "v",
    "e",
    "r",
    "y",
    "t",
    "h",
    "i",
    "n",
    "g",
    ".",
    " ",
    "A",
    "I",
    "-",
    "g",
    "e",
    "n",
    "e",
    "r",
    "a",
    "t",
    "e",
    "d",
    " ",
    "c",
    "o",
    "d",
    "e",
    " ",
    "i",
    "s",
    " ",
    "n",
    "o",
    "t",
    " ",
    "a",
    "l",
    "l",
    "o",
    "w",
    "e",
    "d",
    " ",
    "o",
    "n",
    " ",
    "a",
    "s",
    "s",
    "i",
    "g",
    "n",
    "m",
    "e",
    "n",
    "t",
    "s",
    " ",
    "i",
    "n",
    " ",
    "t",
    "h",
    "i",
    "s",
    " ",
    "c",
    "o",
    "u",
    "r",
    "s",
    "e",
    "."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules and settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef4fa87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T19:39:41.828087Z",
     "start_time": "2022-09-19T19:39:41.818897Z"
    }
   },
   "outputs": [],
   "source": [
    "# first thing is to import pandas\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 20\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-lab (do before class)\n",
    "\n",
    "We’ll build the core workflow in a small example first, then repeat it on the Maryland dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 — Warm-up: metrics on a tiny table\n",
    "\n",
    "We’ll treat:\n",
    "- `y` as the true outcome (0/1)\n",
    "- `prediction` as a model’s predicted probability for `y = 1`\n",
    "\n",
    "Then we’ll create ŷ by choosing a threshold and compute TPR and PPV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: From a probability to a predicted label\n",
    "\n",
    "A model gives a number like `prediction = 0.73`. Think of it as: \n",
    "> the model’s estimated probability that `y = 1`\n",
    "\n",
    "To make a yes/no prediction, we pick a **threshold** `t` and define:\n",
    "- predict $\\hat{y} = 1$ if `prediction ≥ t`\n",
    "- predict $\\hat{y} = 0$ if `prediction < t`\n",
    "\n",
    "Changing `t` changes how many people we predict as positive, which changes the error types we make.\n",
    "\n",
    "### Step 1: Confusion matrix (four outcomes)\n",
    "\n",
    "Once you have `y` and $\\hat{y}$, every row is one of:\n",
    "- **TP**: `y = 1` and $\\hat{y} = 1$\n",
    "- **FP**: `y = 0` and $\\hat{y} = 1$\n",
    "- **TN**: `y = 0` and $\\hat{y} = 0$\n",
    "- **FN**: `y = 1` and $\\hat{y} = 0$\n",
    "\n",
    "In Pandas, `value_counts` on two columns is a fast way to compute those counts.\n",
    "\n",
    "### Step 1.5: Recode booleans into 0/1\n",
    "\n",
    "When we apply a threshold, we naturally get a `True/False` value (did the prediction clear the threshold?).\n",
    "For the rest of the lab, it’s convenient to also have a `0/1` version.\n",
    "\n",
    "We’ll use Pandas `map` to recode values like this:\n",
    "- `True → 1`\n",
    "- `False → 0`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy = pd.DataFrame({\n",
    "    'prediction': [0.95, 0.80, 0.73, 0.68, 0.60, 0.55, 0.52, 0.49, 0.30, 0.18],\n",
    "    'y':          [1,    0,    1,    1,    0,    1,    0,    1,    0,    0],\n",
    "})\n",
    "df_toy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy table:\n",
    "- `y = 1` means the outcome happened.\n",
    "- `prediction` is the model’s score (higher means the model thinks `y = 1` is more likely).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy['yhat'] = df_toy['prediction'] >= 0.5\n",
    "\n",
    "# map: recode True/False into 1/0\n",
    "df_toy['yhat01'] = df_toy['yhat'].map({True: 1, False: 0})\n",
    "\n",
    "df_toy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s what we just did:\n",
    "- `yhat` is `True/False` (a boolean).\n",
    "- `yhat01` converts that to `1/0` using `map`, which is convenient for counting and probability calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_counts_toy = df_toy[['y', 'yhat01']].value_counts().sort_index()\n",
    "joint_counts_toy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_counts` on `['y', 'yhat01']` gives counts for each pair `( y , \\hat{y} )`.\n",
    "\n",
    "Interpretation example: `( 1 , 1 )` is the number of rows where the outcome is 1 and the prediction is 1 (that’s **TP**).\n",
    "\n",
    "We’ll use those four counts to compute TPR and PPV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Metrics as conditional probabilities\n",
    "\n",
    "- **TPR / Recall** = $P ( \\hat{y} = 1 \\mid y = 1 ) = \\frac{TP}{TP + FN}$\n",
    "- **PPV / Precision** = $P ( y = 1 \\mid \\hat{y} = 1 ) = \\frac{TP}{TP + FP}$\n",
    "\n",
    "Notice the denominators:\n",
    "- TPR conditions on **actual positives** (`y = 1`).\n",
    "- PPV conditions on **predicted positives** (`\\hat{y} = 1`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_toy = joint_counts_toy.unstack(fill_value=0).reindex(index=[0, 1], columns=[0, 1], fill_value=0)\n",
    "cm_toy.index = ['y = 0', 'y = 1']\n",
    "cm_toy.columns = ['yhat = 0', 'yhat = 1']\n",
    "\n",
    "TN = int(cm_toy.iloc[0, 0])\n",
    "FP = int(cm_toy.iloc[0, 1])\n",
    "FN = int(cm_toy.iloc[1, 0])\n",
    "TP = int(cm_toy.iloc[1, 1])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "PPV = TP / (TP + FP)\n",
    "\n",
    "summary_counts = pd.DataFrame({'Count': [TP, FP, TN, FN]}, index=['TP', 'FP', 'TN', 'FN'])\n",
    "summary_metrics = pd.DataFrame({'Value': [TPR, PPV]}, index=['TPR (Recall)', 'PPV (Precision)']).round(3)\n",
    "\n",
    "cm_toy\n",
    "summary_counts\n",
    "summary_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** lower the threshold to 0.3. What happens to TPR? What happens to PPV?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pattern is:\n",
    "- Lower threshold → predict more positives → **TPR tends to go up** (you miss fewer true positives)\n",
    "- But you may also predict more false positives → **PPV can go down**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy['yhat01_03'] = (df_toy['prediction'] >= 0.3).map({True: 1, False: 0})\n",
    "joint_counts_toy_03 = df_toy[['y', 'yhat01_03']].value_counts().sort_index()\n",
    "\n",
    "cm_toy_03 = joint_counts_toy_03.unstack(fill_value=0).reindex(index=[0, 1], columns=[0, 1], fill_value=0)\n",
    "cm_toy_03.index = ['y = 0', 'y = 1']\n",
    "cm_toy_03.columns = ['yhat = 0', 'yhat = 1']\n",
    "\n",
    "FP = int(cm_toy_03.iloc[0, 1])\n",
    "FN = int(cm_toy_03.iloc[1, 0])\n",
    "TP = int(cm_toy_03.iloc[1, 1])\n",
    "\n",
    "TPR_03 = TP / (TP + FN)\n",
    "PPV_03 = TP / (TP + FP)\n",
    "\n",
    "summary_metrics_03 = pd.DataFrame({'Value': [TPR_03, PPV_03]}, index=['TPR (Recall)', 'PPV (Precision)']).round(3)\n",
    "\n",
    "cm_toy_03\n",
    "summary_metrics_03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Conditional independence (preview for Naive Bayes)\n",
    "\n",
    "Naive Bayes works by multiplying probabilities like $P ( A = 1 \\mid y ) \\times P ( B = 1 \\mid y )$.\n",
    "That multiplication is only exactly valid if the features are **conditionally independent** given $y$.\n",
    "\n",
    "**Conditional independence idea:** within a fixed value of $y$, knowing $A$ shouldn’t tell you anything extra about $B$.\n",
    "Mathematically, one way to write this is:\n",
    "\n",
    "- $P ( A = 1 , B = 1 \\mid y ) = P ( A = 1 \\mid y ) \\times P ( B = 1 \\mid y )$\n",
    "\n",
    "We’ll check that with a tiny toy table where $A$ and $B$ are binary (0/1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_y0 = ([{'y': 0, 'A': 0, 'B': 0}] * 4\n",
    "           + [{'y': 0, 'A': 0, 'B': 1}] * 4\n",
    "           + [{'y': 0, 'A': 1, 'B': 0}] * 4\n",
    "           + [{'y': 0, 'A': 1, 'B': 1}] * 4)\n",
    "\n",
    "rows_y1 = ([{'y': 1, 'A': 0, 'B': 0}] * 4\n",
    "           + [{'y': 1, 'A': 1, 'B': 1}] * 4)\n",
    "\n",
    "df_ci = pd.DataFrame(rows_y0 + rows_y1)\n",
    "df_ci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Check conditional independence for $A$ and $B$ separately for $y = 0$ and for $y = 1$.\n",
    "\n",
    "For each value of $y$, compute:\n",
    "- $P ( A = 1 , B = 1 \\mid y )$\n",
    "- $P ( A = 1 \\mid y ) \\times P ( B = 1 \\mid y )$\n",
    "\n",
    "Are they the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conditional_independence(df, y_value):\n",
    "    sub = df[df['y'] == y_value]\n",
    "    p_joint = ((sub['A'] == 1) & (sub['B'] == 1)).mean()\n",
    "    p_a = (sub['A'] == 1).mean()\n",
    "    p_b = (sub['B'] == 1).mean()\n",
    "    p_prod = p_a * p_b\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Value': [p_joint, p_a, p_b, p_prod]\n",
    "    }, index=[\n",
    "        'P(A=1, B=1 | y)',\n",
    "        'P(A=1 | y)',\n",
    "        'P(B=1 | y)',\n",
    "        'P(A=1 | y) * P(B=1 | y)'\n",
    "    ]).round(3)\n",
    "\n",
    "check_conditional_independence(df_ci, 0)\n",
    "check_conditional_independence(df_ci, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 — Maryland dataset\n",
    "\n",
    "This lab uses a dataset with:\n",
    "- a **model prediction** (a probability between 0 and 1), and\n",
    "- a **binary outcome** (0/1).\n",
    "\n",
    "Our goal is to practice turning a probability into a predicted label using a threshold, then computing performance metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the columns mean (for this lab)\n",
    "\n",
    "- `umd_id`: an ID for each person (not a feature for prediction).\n",
    "- `outcome_violent_rearrest`: the true label $y$ (0/1). In the raw data it may show up as `0.0`/`1.0`, but we treat it as 0/1.\n",
    "- `prediction`: the model’s predicted probability that $y = 1$.\n",
    "\n",
    "We’ll also use a few columns to build toy features:\n",
    "- `age_at_arrest`: age (in years) at the time of arrest.\n",
    "- `n_vio_convictions_last_4yrs`: number of violent convictions in the last 4 years.\n",
    "- `n_vio_convictions_last_180days`: number of violent convictions in the last 180 days.\n",
    "- `n_vio_arrests_last_4yrs`: number of violent arrests in the last 4 years.\n",
    "- `n_vio_arrests_last_180days`: number of violent arrests in the last 180 days.\n",
    "\n",
    "Workflow (same as the toy example): choose a threshold, build $\\hat{y}$, then compute metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e86cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>umd_id</th>\n",
       "      <th>outcome_violent_rearrest</th>\n",
       "      <th>prediction</th>\n",
       "      <th>n_vio_convictions_last_4yrs</th>\n",
       "      <th>n_vio_convictions_last_180days</th>\n",
       "      <th>n_vio_arrests_last_4yrs</th>\n",
       "      <th>n_vio_arrests_last_180days</th>\n",
       "      <th>age_at_arrest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5974815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.060274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5835352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.420702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.717808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7222541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.427397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5031868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.186301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3532116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.764384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    umd_id  outcome_violent_rearrest  prediction  n_vio_convictions_last_4yrs  \\\n",
       "0  5974815                       0.0    0.084093                          0.0   \n",
       "1  5835352                       1.0    0.420702                          0.0   \n",
       "2  7222541                       0.0    0.124549                          0.0   \n",
       "3  5031868                       1.0    0.181424                          0.0   \n",
       "4  3532116                       0.0    0.114881                          0.0   \n",
       "\n",
       "   n_vio_convictions_last_180days  n_vio_arrests_last_4yrs  \\\n",
       "0                             0.0                      0.0   \n",
       "1                             0.0                      0.0   \n",
       "2                             0.0                      0.0   \n",
       "3                             0.0                      0.0   \n",
       "4                             0.0                      0.0   \n",
       "\n",
       "   n_vio_arrests_last_180days  age_at_arrest  \n",
       "0                         0.0      35.060274  \n",
       "1                         0.0      19.717808  \n",
       "2                         0.0      56.427397  \n",
       "3                         0.0      25.186301  \n",
       "4                         0.0      28.764384  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab4_data = pd.read_csv('https://www.dropbox.com/scl/fi/0nhbo32tdw7mi2v2g0vd0/lab5_dataset.csv?rlkey=e0oevkrciv91r53rricdesq00&dl=1')\n",
    "lab4_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ad9d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab4_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll mostly work with three columns for the metrics part:\n",
    "- `y`\n",
    "- `prediction`\n",
    "- `yhat01`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab4_data['y'] = lab4_data['outcome_violent_rearrest']\n",
    "lab4_data['yhat'] = lab4_data['prediction'] >= 0.5\n",
    "lab4_data['yhat01'] = lab4_data['yhat'].map({True: 1, False: 0})\n",
    "\n",
    "lab4_data[['y', 'yhat01']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_counts = lab4_data[['y', 'yhat01']].value_counts().sort_index()\n",
    "joint_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the toy example, `joint_counts` contains the four confusion-matrix counts (TP, FP, TN, FN), indexed by `( y , \\hat{y} )`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joint_counts.unstack(fill_value=0).reindex(index=[0, 1], columns=[0, 1], fill_value=0)\n",
    "cm.index = ['y = 0', 'y = 1']\n",
    "cm.columns = ['yhat = 0', 'yhat = 1']\n",
    "\n",
    "FP = int(cm.iloc[0, 1])\n",
    "FN = int(cm.iloc[1, 0])\n",
    "TP = int(cm.iloc[1, 1])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "PPV = TP / (TP + FP)\n",
    "\n",
    "metrics_md = pd.DataFrame({'Value': [TPR, PPV]}, index=['TPR (Recall)', 'PPV (Precision)']).round(3)\n",
    "\n",
    "cm\n",
    "metrics_md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 — Pandas functions we’ll keep using\n",
    "\n",
    "You’ve already seen one of these (`map`) in the toy example. Here are three small functions that show up constantly in data science work:\n",
    "\n",
    "- `sort_values`: sort a DataFrame by a column (we’ll rank people by predicted risk).\n",
    "- `between`: create a boolean for whether a value falls in a range (we’ll define an age group).\n",
    "- `map`: recode values (we’ll convert `True/False` into `1/0`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_values: rank people by predicted risk (highest first)\n",
    "ranked = lab4_data.sort_values('prediction', ascending=False)\n",
    "ranked[['prediction', 'y']].head()\n",
    "\n",
    "# Example: PPV among the top 100 highest-risk people\n",
    "ppv_top_100 = ranked.head(100)['y'].mean()\n",
    "ppv_top_100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea above is the same as the in-class “top 500” task — it’s just using a different K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# between example\n",
    "lab4_data['young_adult'] = lab4_data['age_at_arrest'].between(18, 25)\n",
    "lab4_data['young_adult01'] = lab4_data['young_adult'].map({True: 1, False: 0})\n",
    "lab4_data[['age_at_arrest', 'young_adult', 'young_adult01']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`between(18, 25)` is often nicer than writing two conditions with `&`.\n",
    "\n",
    "It returns `True/False`. In this course we often map that to `1/0` so we can treat it like an indicator variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map example\n",
    "pd.Series([True, False, True]).map({True: 1, False: 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map` is a general recoding tool. We’ll use it mostly to turn booleans into `1/0`, but you can also map categories (like `'M'` → `'Male'`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Tasks (in class)\n",
    "\n",
    "You should come to class having completed the pre-lab above.\n",
    "In class, we’ll work through these tasks together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Changing the threshold changes the metrics\n",
    "\n",
    "1) Compute the base rate `base_rate = P ( y = 1 )`.\n",
    "\n",
    "Then create `yhat_new` that is 1 if `prediction >= base_rate` and 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute TPR and PPV for `yhat_new`, and compare them to the threshold-0.5 values you computed in the pre-lab.\n",
    "\n",
    "In 1–2 sentences: why might TPR go up while PPV goes down?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Rank-based thresholding (top K)\n",
    "\n",
    "3) Sort `lab4_data` by `prediction` from highest to lowest.\n",
    "\n",
    "Compute the PPV among the **top 500** rows (treat “top 500” as being predicted positive).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Naive Bayes classification\n",
    "\n",
    "We’ll classify based on two features:\n",
    "- `young_adult` (18–25 inclusive)\n",
    "- `vio_conv_gt1` meaning `n_vio_convictions__last_4_years > 1`\n",
    "\n",
    "4) Create `vio_conv_gt1` and convert it to 0/1 if helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Compute the pieces you need for the `y = 1` score and compute:\n",
    "\n",
    "`score_1 = P ( y = 1 ) * P ( young_adult = 1 \\mid y = 1 ) * P ( vio_conv_gt1 = 1 \\mid y = 1 )`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Compute `score_0` similarly, then classify as `y = 1` if `score_1 > score_0` and `y = 0` otherwise.\n",
    "\n",
    "In 1 sentence: what does Naive Bayes assume when it multiplies those conditional probabilities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "5ade917c15395e7ed88b1e8a3f8554ff754a526a8e0b703e5d887afe50fc6c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}