{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72fe8f-27bb-43ca-910a-6439fcb71c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from plotnine import * # Import plotnine\n",
    "import warnings\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_CODING_RESULTS_FILE = \"deductive_coding_results_multi_model.json\"\n",
    "# Define a threshold for considering a prediction valid (optional)\n",
    "# For now, we count any identified topic/subtopic regardless of confidence\n",
    "# CONFIDENCE_THRESHOLD = 3\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def calculate_metrics(tp, fp, fn):\n",
    "    \"\"\"Calculates Precision, Recall, and F1-Score.\"\"\"\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "def safe_get(data, keys, default=None):\n",
    "    \"\"\"Safely get nested dictionary values.\"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        return default\n",
    "    temp = data\n",
    "    for key in keys:\n",
    "        if isinstance(temp, dict) and key in temp:\n",
    "            temp = temp[key]\n",
    "        else:\n",
    "            return default\n",
    "    return temp\n",
    "\n",
    "results_file = INPUT_CODING_RESULTS_FILE\n",
    "\n",
    "with open(results_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Converted results to DataFrame.\")\n",
    "\n",
    "# --- Data Cleaning and Preparation ---\n",
    "\n",
    "# Filter out entries with coding errors\n",
    "initial_count = len(df)\n",
    "# df = df[df['error'].isna()] # Assumes 'error' key exists for errors\n",
    "df = df[df['coding_result'].apply(lambda x: isinstance(x, dict) and 'error' not in x)]\n",
    "print(f\"Filtered out {initial_count - len(df)} entries with coding errors.\")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No valid coding results found after filtering errors.\")\n",
    "\n",
    "\n",
    "# Extract ground truth information safely\n",
    "df['gt_topics'] = df['ground_truth'].apply(lambda x: set(k for k, v in safe_get(x, ['topic_mix'], {}).items() if v is not None))\n",
    "df['gt_subtopics'] = df['ground_truth'].apply(lambda x: set(v for k, v in safe_get(x, ['selected_subtopics'], {}).items() if v is not None))\n",
    "\n",
    "# Extract predicted topics and subtopics safely\n",
    "df['pred_topics'] = df['coding_result'].apply(lambda x: set(t['topic_id'] for t in safe_get(x, ['topics'], []) if isinstance(t, dict) and 'topic_id' in t))\n",
    "# Extract predicted subtopic names\n",
    "df['pred_subtopics'] = df['coding_result'].apply(lambda x: set(s['subtopic_name'] for s in safe_get(x, ['subtopics'], []) if isinstance(s, dict) and 'subtopic_name' in s))\n",
    "\n",
    "# Extract grouping parameters from ground_truth safely\n",
    "df['domain'] = df['ground_truth'].apply(lambda x: safe_get(x, ['domain'], 'N/A'))\n",
    "df['diversity_type'] = df['ground_truth'].apply(lambda x: safe_get(x, ['diversity_type'], 'N/A'))\n",
    "df['allow_topic_mention'] = df['ground_truth'].apply(lambda x: safe_get(x, ['allow_topic_mention'], 'N/A'))\n",
    "df['allow_subtopic_mention'] = df['ground_truth'].apply(lambda x: safe_get(x, ['allow_subtopic_mention'], 'N/A'))\n",
    "\n",
    "# Extract individual diversity parameters (handle missing/None)\n",
    "diversity_param_keys = [\n",
    "    'concept_blending', 'concept_granularity', 'interdisciplinary_orientation',\n",
    "    'methodological_approaches', 'rhetorical_structures', 'temporal_context',\n",
    "    'terminology_density'\n",
    "]\n",
    "\n",
    "for key in diversity_param_keys:\n",
    "    df[key] = df['ground_truth'].apply(lambda x: safe_get(x, ['diversity_params', key], 'N/A'))\n",
    "    df[key] = df[key].fillna('N/A') # Replace None/NaN with 'N/A' for grouping\n",
    "\n",
    "print(\"Extracted ground truth, predictions, and grouping parameters.\")\n",
    "\n",
    "# --- Calculate TP, FP, FN per row ---\n",
    "print(\"Calculating TP, FP, FN for each entry...\")\n",
    "\n",
    "# Topics\n",
    "df['tp_topics'] = df.apply(lambda row: len(row['gt_topics'].intersection(row['pred_topics'])), axis=1)\n",
    "df['fp_topics'] = df.apply(lambda row: len(row['pred_topics'].difference(row['gt_topics'])), axis=1)\n",
    "df['fn_topics'] = df.apply(lambda row: len(row['gt_topics'].difference(row['pred_topics'])), axis=1)\n",
    "\n",
    "# Subtopics\n",
    "df['tp_subtopics'] = df.apply(lambda row: len(row['gt_subtopics'].intersection(row['pred_subtopics'])), axis=1)\n",
    "df['fp_subtopics'] = df.apply(lambda row: len(row['pred_subtopics'].difference(row['gt_subtopics'])), axis=1)\n",
    "df['fn_subtopics'] = df.apply(lambda row: len(row['gt_subtopics'].difference(row['pred_subtopics'])), axis=1)\n",
    "\n",
    "print(\"Calculations complete.\")\n",
    "\n",
    "# --- Grouping and Aggregation ---\n",
    "grouping_vars = [\n",
    "    'domain',\n",
    "    'diversity_type',\n",
    "    'generating_model',\n",
    "    'coding_model',\n",
    "    'allow_topic_mention',\n",
    "    'allow_subtopic_mention'\n",
    "] + diversity_param_keys\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "for group_var in grouping_vars:\n",
    "    print(f\"\\n--- Analyzing by: {group_var} ---\")\n",
    "\n",
    "    if group_var not in df.columns:\n",
    "        print(f\"Warning: Grouping variable '{group_var}' not found in DataFrame. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Group data\n",
    "    grouped = df.groupby(group_var).agg(\n",
    "        total_entries=('original_variation_id', 'count'), # Count entries per group\n",
    "        # Sum TP/FP/FN across the group\n",
    "        sum_tp_topics=('tp_topics', 'sum'),\n",
    "        sum_fp_topics=('fp_topics', 'sum'),\n",
    "        sum_fn_topics=('fn_topics', 'sum'),\n",
    "        sum_tp_subtopics=('tp_subtopics', 'sum'),\n",
    "        sum_fp_subtopics=('fp_subtopics', 'sum'),\n",
    "        sum_fn_subtopics=('fn_subtopics', 'sum')\n",
    "    )\n",
    "\n",
    "    # Calculate metrics for each group\n",
    "    results_list = []\n",
    "    for group_name, row in grouped.iterrows():\n",
    "        # Topic Metrics\n",
    "        prec_t, recall_t, f1_t = calculate_metrics(row['sum_tp_topics'], row['sum_fp_topics'], row['sum_fn_topics'])\n",
    "        # Subtopic Metrics\n",
    "        prec_s, recall_s, f1_s = calculate_metrics(row['sum_tp_subtopics'], row['sum_fp_subtopics'], row['sum_fn_subtopics'])\n",
    "\n",
    "        results_list.append({\n",
    "            group_var: group_name,\n",
    "            'Total Entries': row['total_entries'],\n",
    "            'TP (Topics)': row['sum_tp_topics'],\n",
    "            'FP (Topics)': row['sum_fp_topics'],\n",
    "            'FN (Topics)': row['sum_fn_topics'],\n",
    "            'Precision (Topics)': prec_t,\n",
    "            'Recall (Topics)': recall_t,\n",
    "            'F1 (Topics)': f1_t,\n",
    "            'TP (Subtopics)': row['sum_tp_subtopics'],\n",
    "            'FP (Subtopics)': row['sum_fp_subtopics'],\n",
    "            'FN (Subtopics)': row['sum_fn_subtopics'],\n",
    "            'Precision (Subtopics)': prec_s,\n",
    "            'Recall (Subtopics)': recall_s,\n",
    "            'F1 (Subtopics)': f1_s,\n",
    "        })\n",
    "\n",
    "    # Convert results for this grouping to DataFrame for better display\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    results_summary[group_var] = results_df\n",
    "\n",
    "    # Print the results for the current grouping\n",
    "    print(results_df.round(3).to_string(index=False)) # Display rounded results\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def plot_evaluation_metrics(results_summary):\n",
    "    \"\"\"\n",
    "    Generates bar plots for Precision, Recall, F1 using plotnine.\n",
    "\n",
    "    Args:\n",
    "        results_summary (dict): Dictionary where keys are grouping variable names\n",
    "                                and values are the summary DataFrames from analyze_coding_results.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Generating Evaluation Plots ---\")\n",
    "\n",
    "    if not results_summary:\n",
    "        print(\"No summary data to plot.\")\n",
    "        return\n",
    "\n",
    "    # Define consistent colors for metrics\n",
    "    metric_colors = {'Precision': '#1f77b4', 'Recall': '#ff7f0e', 'F1': '#2ca02c'} # Example colors\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "         warnings.simplefilter(\"ignore\", category=UserWarning) # Suppress plotnine warnings if needed\n",
    "\n",
    "         for group_var, summary_df in results_summary.items():\n",
    "             print(f\"\\nPlotting metrics for grouping: {group_var}\")\n",
    "\n",
    "             if summary_df.empty or len(summary_df) == 0:\n",
    "                 print(f\"Skipping empty or invalid summary for {group_var}\")\n",
    "                 continue\n",
    "\n",
    "             # Ensure the grouping variable column exists after potential reset_index\n",
    "             if group_var not in summary_df.columns:\n",
    "                  print(f\"Warning: Column '{group_var}' not found in summary DataFrame for plotting. Skipping.\")\n",
    "                  continue\n",
    "\n",
    "             # Convert grouping variable to string/category for plotting stability\n",
    "             try:\n",
    "                 summary_df[group_var] = summary_df[group_var].astype(str)\n",
    "             except Exception as e:\n",
    "                  print(f\"Warning: Could not convert group var '{group_var}' to string: {e}. Plotting might fail.\")\n",
    "\n",
    "\n",
    "             # --- Prepare data for Topic plots ---\n",
    "             topic_cols = ['Precision (Topics)', 'Recall (Topics)', 'F1 (Topics)']\n",
    "             if not all(col in summary_df.columns for col in topic_cols):\n",
    "                  print(f\"Warning: Missing topic metric columns for {group_var}. Skipping topic plot.\")\n",
    "             else:\n",
    "                  topic_metrics_df = summary_df[[group_var] + topic_cols].copy()\n",
    "                  topic_metrics_df.rename(columns={\n",
    "                      'Precision (Topics)': 'Precision',\n",
    "                      'Recall (Topics)': 'Recall',\n",
    "                      'F1 (Topics)': 'F1'\n",
    "                  }, inplace=True)\n",
    "                  try:\n",
    "                       topic_melted = pd.melt(topic_metrics_df,\n",
    "                                                id_vars=[group_var],\n",
    "                                                var_name='Metric Type',\n",
    "                                                value_name='Score')\n",
    "                       topic_melted['Metric Type'] = pd.Categorical(topic_melted['Metric Type'], categories=['Precision', 'Recall', 'F1']) # Ensure order\n",
    "                  except Exception as melt_e:\n",
    "                       print(f\"ERROR during topic data melting for {group_var}: {melt_e}\")\n",
    "                       continue # Skip plotting for this variable\n",
    "\n",
    "\n",
    "                  # --- Generate Topic Plot ---\n",
    "                  try:\n",
    "                      topic_plot = (\n",
    "                          ggplot(topic_melted, aes(x='Metric Type', y='Score', fill=group_var))\n",
    "                          + geom_col(position=position_dodge(width=0.9), na_rm=True) # Dodge bars, remove NA scores\n",
    "                          + labs(title=f'Topic Identification Metrics by {group_var.replace(\"_\", \" \").title()}',\n",
    "                                 x=group_var.replace('_', ' ').title(), # Nicer axis label\n",
    "                                 y='Score (0-1)',\n",
    "                                 fill='Metric') # Legend title\n",
    "                          + ylim(0, 1.05) # Extend slightly beyond 1 for visibility\n",
    "                          + theme_minimal(base_size=10) # Adjust base font size if needed\n",
    "                          + theme(axis_text_x=element_text(angle=45, hjust=1, size=8), # Rotate labels, adjust size\n",
    "                                  plot_title=element_text(size=12),\n",
    "                                  figure_size=(max(6, len(topic_melted[group_var].unique()) * 0.8), 4)) # Dynamic width\n",
    "                          # + scale_fill_manual(values=metric_colors) + # Use defined colors\n",
    "                          + theme(plot_background=element_rect(fill='white'), panel_background=element_rect(fill='white'))\n",
    "                      )\n",
    "                      print(topic_plot) # Display the plot\n",
    "                  except Exception as e:\n",
    "                      print(f\"ERROR generating topic plot for {group_var}: {e}\")\n",
    "\n",
    "\n",
    "             # --- Prepare data for Subtopic plots ---\n",
    "             subtopic_cols = ['Precision (Subtopics)', 'Recall (Subtopics)', 'F1 (Subtopics)']\n",
    "             if not all(col in summary_df.columns for col in subtopic_cols):\n",
    "                  print(f\"Warning: Missing subtopic metric columns for {group_var}. Skipping subtopic plot.\")\n",
    "             else:\n",
    "                  subtopic_metrics_df = summary_df[[group_var] + subtopic_cols].copy()\n",
    "                  subtopic_metrics_df.rename(columns={\n",
    "                      'Precision (Subtopics)': 'Precision',\n",
    "                      'Recall (Subtopics)': 'Recall',\n",
    "                      'F1 (Subtopics)': 'F1'\n",
    "                  }, inplace=True)\n",
    "                  try:\n",
    "                       subtopic_melted = pd.melt(subtopic_metrics_df,\n",
    "                                                   id_vars=[group_var],\n",
    "                                                   var_name='Metric Type',\n",
    "                                                   value_name='Score')\n",
    "                       subtopic_melted['Metric Type'] = pd.Categorical(subtopic_melted['Metric Type'], categories=['Precision', 'Recall', 'F1']) # Ensure order\n",
    "                  except Exception as melt_e:\n",
    "                       print(f\"ERROR during subtopic data melting for {group_var}: {melt_e}\")\n",
    "                       continue # Skip plotting for this variable\n",
    "\n",
    "\n",
    "                  # --- Generate Subtopic Plot ---\n",
    "                  try:\n",
    "                      subtopic_plot = (\n",
    "                          ggplot(subtopic_melted, aes(x='Metric Type', y='Score', fill=group_var))\n",
    "                          + geom_col(position=position_dodge(width=0.9), na_rm=True) # Dodge bars, remove NA scores\n",
    "                          + labs(title=f'Subtopic Identification Metrics by {group_var.replace(\"_\", \" \").title()}',\n",
    "                                 x=group_var.replace('_', ' ').title(), # Nicer axis label\n",
    "                                 y='Score (0-1)',\n",
    "                                 fill='Metric') # Legend title\n",
    "                          + ylim(0, 1.05) # Extend slightly beyond 1\n",
    "                          + theme_minimal(base_size=10)\n",
    "                          + theme(axis_text_x=element_text(angle=45, hjust=1, size=8), # Rotate labels, adjust size\n",
    "                                  plot_title=element_text(size=12),\n",
    "                                  figure_size=(max(6, len(subtopic_melted[group_var].unique()) * 0.8), 4)) # Dynamic width\n",
    "                          #+ scale_fill_manual(values=metric_colors) + # Use defined colors\n",
    "                          + theme(plot_background=element_rect(fill='white'), panel_background=element_rect(fill='white'))\n",
    "                      )\n",
    "                      print(subtopic_plot) # Display the plot\n",
    "                  except Exception as e:\n",
    "                      print(f\"ERROR generating subtopic plot for {group_var}: {e}\")\n",
    "\n",
    "    print(\"\\n--- Plotting Complete ---\")\n",
    "\n",
    "\n",
    "plot_evaluation_metrics(results_summary)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from plotnine import * # Import plotnine\n",
    "import warnings\n",
    "import re # Import regex for parsing keys later\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_CODING_RESULTS_FILE = \"deductive_coding_results_multi_model.json\"\n",
    "# Define a threshold for considering a prediction valid (optional)\n",
    "# CONFIDENCE_THRESHOLD = 3\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def calculate_metrics(tp, fp, fn):\n",
    "    \"\"\"Calculates Precision, Recall, and F1-Score.\"\"\"\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    # Handle potential NaN if precision and recall are both 0\n",
    "    if np.isnan(f1):\n",
    "        f1 = 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "def safe_get(data, keys, default=None):\n",
    "    \"\"\"Safely get nested dictionary values.\"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        return default\n",
    "    temp = data\n",
    "    for key in keys:\n",
    "        if isinstance(temp, dict) and key in temp:\n",
    "            temp = temp[key]\n",
    "        else:\n",
    "            return default\n",
    "    return temp\n",
    "\n",
    "def analyze_coding_results(results_file):\n",
    "    \"\"\"\n",
    "    Loads coding results, calculates TP/FP/FN, aggregates metrics by single\n",
    "    variables and nested variables (by coding/generating model).\n",
    "    Returns a dictionary of summary DataFrames.\n",
    "    \"\"\"\n",
    "    print(f\"Loading coding results from: {results_file}\")\n",
    "    try:\n",
    "        with open(results_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"Loaded {len(data)} entries.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File not found at {results_file}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ERROR: Failed to decode JSON from {results_file}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred loading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Converted results to DataFrame.\")\n",
    "\n",
    "    # --- Data Cleaning and Preparation ---\n",
    "    initial_count = len(df)\n",
    "    df = df[df['error'].isna()] if 'error' in df.columns else df\n",
    "    df = df[df['coding_result'].apply(lambda x: isinstance(x, dict) and 'error' not in x)]\n",
    "    df = df[df['coding_result'].apply(lambda x: isinstance(x, dict))]\n",
    "    print(f\"Filtered out {initial_count - len(df)} entries with coding errors or invalid format.\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"No valid coding results found after filtering errors.\")\n",
    "        return None\n",
    "\n",
    "    # Extract ground truth sets\n",
    "    df['gt_topics'] = df['ground_truth'].apply(lambda x: set(k for k, v in safe_get(x, ['topic_mix'], {}).items() if v is not None))\n",
    "    df['gt_subtopics'] = df['ground_truth'].apply(lambda x: set(v for k, v in safe_get(x, ['selected_subtopics'], {}).items() if v is not None))\n",
    "\n",
    "    # Extract predicted sets\n",
    "    df['pred_topics'] = df['coding_result'].apply(\n",
    "        lambda x: set(t['topic_id'] for t in safe_get(x, ['topics'], []) if isinstance(t, dict) and 'topic_id' in t)\n",
    "                  if isinstance(safe_get(x, ['topics']), list) else set()\n",
    "    )\n",
    "    df['pred_subtopics'] = df['coding_result'].apply(\n",
    "        lambda x: set(s['subtopic_name'] for s in safe_get(x, ['subtopics'], []) if isinstance(s, dict) and 'subtopic_name' in s)\n",
    "                  if isinstance(safe_get(x, ['subtopics']), list) else set()\n",
    "    )\n",
    "\n",
    "    # Extract grouping parameters safely\n",
    "    df['domain'] = df['ground_truth'].apply(lambda x: safe_get(x, ['domain'], 'N/A')).fillna('N/A')\n",
    "    df['diversity_type'] = df['ground_truth'].apply(lambda x: safe_get(x, ['diversity_type'], 'N/A')).fillna('N/A')\n",
    "    df['allow_topic_mention'] = df['ground_truth'].apply(lambda x: safe_get(x, ['allow_topic_mention'], 'N/A')).fillna('N/A').astype(str) # Convert bool to str\n",
    "    df['allow_subtopic_mention'] = df['ground_truth'].apply(lambda x: safe_get(x, ['allow_subtopic_mention'], 'N/A')).fillna('N/A').astype(str) # Convert bool to str\n",
    "\n",
    "    df['generating_model'] = df['generating_model'].fillna('N/A') if 'generating_model' in df.columns else 'N/A'\n",
    "    df['coding_model'] = df['coding_model'].fillna('N/A') if 'coding_model' in df.columns else 'N/A'\n",
    "\n",
    "    diversity_param_keys = [\n",
    "        'concept_blending', 'concept_granularity', 'interdisciplinary_orientation',\n",
    "        'methodological_approaches', 'rhetorical_structures', 'temporal_context',\n",
    "        'terminology_density'\n",
    "    ]\n",
    "    for key in diversity_param_keys:\n",
    "        df[key] = df['ground_truth'].apply(lambda x: safe_get(x, ['diversity_params', key], 'N/A'))\n",
    "        df[key] = df[key].fillna('N/A').astype(str)\n",
    "\n",
    "    print(\"Extracted ground truth, predictions, and grouping parameters.\")\n",
    "\n",
    "    # --- Calculate TP, FP, FN per row ---\n",
    "    df['tp_topics'] = df.apply(lambda row: len(row['gt_topics'].intersection(row['pred_topics'])), axis=1)\n",
    "    df['fp_topics'] = df.apply(lambda row: len(row['pred_topics'].difference(row['gt_topics'])), axis=1)\n",
    "    df['fn_topics'] = df.apply(lambda row: len(row['gt_topics'].difference(row['pred_topics'])), axis=1)\n",
    "    df['tp_subtopics'] = df.apply(lambda row: len(row['gt_subtopics'].intersection(row['pred_subtopics'])), axis=1)\n",
    "    df['fp_subtopics'] = df.apply(lambda row: len(row['pred_subtopics'].difference(row['gt_subtopics'])), axis=1)\n",
    "    df['fn_subtopics'] = df.apply(lambda row: len(row['gt_subtopics'].difference(row['pred_subtopics'])), axis=1)\n",
    "    print(\"Calculated TP, FP, FN.\")\n",
    "\n",
    "    # --- Aggregation Function ---\n",
    "    def aggregate_and_calculate(grouped_df):\n",
    "        \"\"\"Helper to aggregate TP/FP/FN and calculate metrics.\"\"\"\n",
    "        agg_results = grouped_df.agg(\n",
    "            total_entries=('original_variation_id', 'count'),\n",
    "            sum_tp_topics=('tp_topics', 'sum'),\n",
    "            sum_fp_topics=('fp_topics', 'sum'),\n",
    "            sum_fn_topics=('fn_topics', 'sum'),\n",
    "            sum_tp_subtopics=('tp_subtopics', 'sum'),\n",
    "            sum_fp_subtopics=('fp_subtopics', 'sum'),\n",
    "            sum_fn_subtopics=('fn_subtopics', 'sum')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Calculate metrics row-wise on aggregated results\n",
    "        metrics = agg_results.apply(\n",
    "            lambda row: pd.Series({\n",
    "                'Precision (Topics)': calculate_metrics(row['sum_tp_topics'], row['sum_fp_topics'], row['sum_fn_topics'])[0],\n",
    "                'Recall (Topics)': calculate_metrics(row['sum_tp_topics'], row['sum_fp_topics'], row['sum_fn_topics'])[1],\n",
    "                'F1 (Topics)': calculate_metrics(row['sum_tp_topics'], row['sum_fp_topics'], row['sum_fn_topics'])[2],\n",
    "                'Precision (Subtopics)': calculate_metrics(row['sum_tp_subtopics'], row['sum_fp_subtopics'], row['sum_fn_subtopics'])[0],\n",
    "                'Recall (Subtopics)': calculate_metrics(row['sum_tp_subtopics'], row['sum_fp_subtopics'], row['sum_fn_subtopics'])[1],\n",
    "                'F1 (Subtopics)': calculate_metrics(row['sum_tp_subtopics'], row['sum_fp_subtopics'], row['sum_fn_subtopics'])[2],\n",
    "            }), axis=1\n",
    "        )\n",
    "        # Combine aggregated counts and calculated metrics\n",
    "        return pd.concat([agg_results, metrics], axis=1)\n",
    "\n",
    "\n",
    "    # --- Perform Grouping and Aggregation ---\n",
    "    results_summary = {}\n",
    "    base_grouping_vars = [\n",
    "        'domain', 'diversity_type', 'generating_model', 'coding_model',\n",
    "        'allow_topic_mention', 'allow_subtopic_mention'\n",
    "    ]\n",
    "    valid_diversity_keys = [key for key in diversity_param_keys if key in df.columns]\n",
    "    all_grouping_vars = base_grouping_vars + valid_diversity_keys\n",
    "\n",
    "    # 1. Single Variable Grouping (as before)\n",
    "    print(\"\\n--- Performing Single Variable Grouping Analysis ---\")\n",
    "    for group_var in all_grouping_vars:\n",
    "        print(f\"  Grouping by: {group_var}\")\n",
    "        if group_var not in df.columns or df[group_var].isnull().all():\n",
    "            print(f\"    Skipping '{group_var}' due to missing column or all null values.\")\n",
    "            continue\n",
    "        try:\n",
    "            grouped_single = df.groupby(group_var, observed=False, dropna=False) # Include NA group if present\n",
    "            results_df = aggregate_and_calculate(grouped_single)\n",
    "            results_summary[group_var] = results_df\n",
    "            print(f\"    Aggregated results for {group_var}.\")\n",
    "            # print(results_df.round(3).to_string(index=False)) # Optional: print table here\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR during single grouping for '{group_var}': {e}\")\n",
    "\n",
    "    # 2. Nested Grouping: By Coding Model, then others\n",
    "    print(\"\\n--- Performing Nested Grouping Analysis (by Coding Model first) ---\")\n",
    "    primary_nest_var1 = 'coding_model'\n",
    "    secondary_vars1 = [v for v in all_grouping_vars if v != primary_nest_var1]\n",
    "    for secondary_var in secondary_vars1:\n",
    "        group_key = f\"by_{primary_nest_var1}_then_{secondary_var}\"\n",
    "        print(f\"  Grouping by: {primary_nest_var1}, {secondary_var}\")\n",
    "        if primary_nest_var1 not in df.columns or secondary_var not in df.columns or \\\n",
    "           df[primary_nest_var1].isnull().all() or df[secondary_var].isnull().all():\n",
    "            print(f\"    Skipping '{group_key}' due to missing columns or all null values.\")\n",
    "            continue\n",
    "        try:\n",
    "            grouped_nested1 = df.groupby([primary_nest_var1, secondary_var], observed=False, dropna=False)\n",
    "            results_df_nested1 = aggregate_and_calculate(grouped_nested1)\n",
    "            results_summary[group_key] = results_df_nested1\n",
    "            print(f\"    Aggregated results for {group_key}.\")\n",
    "            # print(results_df_nested1.round(3).to_string(index=False)) # Optional: print table here\n",
    "        except Exception as e:\n",
    "             print(f\"    ERROR during nested grouping for '{group_key}': {e}\")\n",
    "\n",
    "    # 3. Nested Grouping: By Generating Model, then others\n",
    "    print(\"\\n--- Performing Nested Grouping Analysis (by Generating Model first) ---\")\n",
    "    primary_nest_var2 = 'generating_model'\n",
    "    secondary_vars2 = [v for v in all_grouping_vars if v != primary_nest_var2]\n",
    "    for secondary_var in secondary_vars2:\n",
    "        group_key = f\"by_{primary_nest_var2}_then_{secondary_var}\"\n",
    "        print(f\"  Grouping by: {primary_nest_var2}, {secondary_var}\")\n",
    "        if primary_nest_var2 not in df.columns or secondary_var not in df.columns or \\\n",
    "           df[primary_nest_var2].isnull().all() or df[secondary_var].isnull().all():\n",
    "            print(f\"    Skipping '{group_key}' due to missing columns or all null values.\")\n",
    "            continue\n",
    "        try:\n",
    "            grouped_nested2 = df.groupby([primary_nest_var2, secondary_var], observed=False, dropna=False)\n",
    "            results_df_nested2 = aggregate_and_calculate(grouped_nested2)\n",
    "            results_summary[group_key] = results_df_nested2\n",
    "            print(f\"    Aggregated results for {group_key}.\")\n",
    "            # print(results_df_nested2.round(3).to_string(index=False)) # Optional: print table here\n",
    "        except Exception as e:\n",
    "             print(f\"    ERROR during nested grouping for '{group_key}': {e}\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Analysis Complete ---\")\n",
    "    return results_summary\n",
    "\n",
    "def plot_evaluation_metrics(results_summary):\n",
    "    \"\"\"\n",
    "    Generates bar plots for Precision, Recall, F1 using plotnine,\n",
    "    handling both single and nested grouping results (using facets for nested).\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Generating Evaluation Plots ---\")\n",
    "\n",
    "    if not results_summary:\n",
    "        print(\"No summary data to plot.\")\n",
    "        return\n",
    "\n",
    "    metric_colors = {'Precision': '#1f77b4', 'Recall': '#ff7f0e', 'F1': '#2ca02c'}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "         warnings.simplefilter(\"ignore\", category=UserWarning) # Suppress plotnine warnings\n",
    "\n",
    "         for key, summary_df in results_summary.items():\n",
    "             print(f\"\\nPlotting metrics for grouping key: {key}\")\n",
    "\n",
    "             if summary_df.empty or len(summary_df) == 0:\n",
    "                 print(f\"  Skipping empty summary for {key}\")\n",
    "                 continue\n",
    "\n",
    "             # Identify grouping type and variables from the key\n",
    "             primary_group_var = None\n",
    "             secondary_group_var = None\n",
    "             plot_title_suffix = \"\"\n",
    "\n",
    "             if key.startswith(\"by_coding_model_then_\"):\n",
    "                 primary_group_var = 'coding_model'\n",
    "                 secondary_group_var = key.replace(\"by_coding_model_then_\", \"\")\n",
    "                 plot_title_suffix = f\" by {secondary_group_var.replace('_', ' ').title()}\\n(Faceted by Coding Model)\"\n",
    "             elif key.startswith(\"by_generating_model_then_\"):\n",
    "                 primary_group_var = 'generating_model'\n",
    "                 secondary_group_var = key.replace(\"by_generating_model_then_\", \"\")\n",
    "                 plot_title_suffix = f\" by {secondary_group_var.replace('_', ' ').title()}\\n(Faceted by Generating Model)\"\n",
    "             else:\n",
    "                 # Single grouping variable\n",
    "                 primary_group_var = key # The key itself is the grouping variable\n",
    "                 plot_title_suffix = f\" by {primary_group_var.replace('_', ' ').title()}\"\n",
    "\n",
    "\n",
    "             # Ensure necessary columns exist\n",
    "             required_plot_cols = [primary_group_var]\n",
    "             if secondary_group_var:\n",
    "                 required_plot_cols.append(secondary_group_var)\n",
    "\n",
    "             if not all(col in summary_df.columns for col in required_plot_cols):\n",
    "                 print(f\"  Warning: Missing grouping columns ({required_plot_cols}) in summary DF for key '{key}'. Skipping plot.\")\n",
    "                 continue\n",
    "\n",
    "             # Convert grouping vars to string for plotting stability\n",
    "             try:\n",
    "                 for col in required_plot_cols:\n",
    "                     summary_df[col] = summary_df[col].astype(str)\n",
    "             except Exception as e:\n",
    "                 print(f\"  Warning: Could not convert grouping columns to string for key '{key}': {e}. Plotting might fail.\")\n",
    "                 continue\n",
    "\n",
    "             # --- Prepare and Plot for Topics ---\n",
    "             topic_cols = ['Precision (Topics)', 'Recall (Topics)', 'F1 (Topics)']\n",
    "             if not all(col in summary_df.columns for col in topic_cols):\n",
    "                  print(f\"  Warning: Missing topic metric columns for {key}. Skipping topic plot.\")\n",
    "             else:\n",
    "                  topic_metrics_df = summary_df[required_plot_cols + topic_cols].copy()\n",
    "                  topic_metrics_df.rename(columns={'Precision (Topics)': 'Precision', 'Recall (Topics)': 'Recall', 'F1 (Topics)': 'F1'}, inplace=True)\n",
    "                  try:\n",
    "                       topic_melted = pd.melt(topic_metrics_df, id_vars=required_plot_cols, var_name='Metric Type', value_name='Score')\n",
    "                       topic_melted['Metric Type'] = pd.Categorical(topic_melted['Metric Type'], categories=['Precision', 'Recall', 'F1'])\n",
    "                  except Exception as melt_e:\n",
    "                       print(f\"  ERROR during topic data melting for {key}: {melt_e}\")\n",
    "                       continue\n",
    "\n",
    "                  # --- Generate Topic Plot ---\n",
    "                  try:\n",
    "                      # Base plot\n",
    "                      p = (ggplot(topic_melted, aes(x='Metric Type', y='Score', fill=secondary_group_var if secondary_group_var else primary_group_var)) \\\n",
    "                          + geom_col(position=position_dodge(width=0.9), na_rm=True) \\\n",
    "                          + labs(title=f'Topic Identification Metrics{plot_title_suffix}',\n",
    "                                 x=(secondary_group_var if secondary_group_var else primary_group_var).replace('_', ' ').title(),\n",
    "                                 y='Score (0-1)', fill='Metric') \\\n",
    "                          + ylim(0, 1.05) \\\n",
    "                          + theme_minimal(base_size=9) \\\n",
    "                          + theme(axis_text_x=element_text(angle=45, hjust=1, size=7),\n",
    "                                  plot_title=element_text(size=11),\n",
    "                                  strip_text=element_text(size=8), # Facet title size\n",
    "                                  figure_size=(max(6, len(summary_df[secondary_group_var if secondary_group_var else primary_group_var].unique()) * (0.6 if secondary_group_var else 0.8)),\n",
    "                                               4 * (len(summary_df[primary_group_var].unique()) if secondary_group_var else 1) )) # Adjust height for facets\n",
    "                          + theme(plot_background=element_rect(fill='white'), panel_background=element_rect(fill='white'))\n",
    "                          )\n",
    "\n",
    "                      # Add facet if it's a nested grouping\n",
    "                      if secondary_group_var and primary_group_var == 'coding_model':\n",
    "                          p += facet_wrap('~coding_model', ncol=1) # Stack facets vertically\n",
    "                      elif secondary_group_var and primary_group_var == 'generating_model':\n",
    "                           p += facet_wrap('~generating_model', ncol=1) # Stack facets vertically\n",
    "\n",
    "                      print(p) # Display the plot\n",
    "\n",
    "                  except Exception as e:\n",
    "                      print(f\"  ERROR generating topic plot for {key}: {e}\")\n",
    "\n",
    "\n",
    "             # --- Prepare and Plot for Subtopics ---\n",
    "             subtopic_cols = ['Precision (Subtopics)', 'Recall (Subtopics)', 'F1 (Subtopics)']\n",
    "             if not all(col in summary_df.columns for col in subtopic_cols):\n",
    "                  print(f\"  Warning: Missing subtopic metric columns for {key}. Skipping subtopic plot.\")\n",
    "             else:\n",
    "                  subtopic_metrics_df = summary_df[required_plot_cols + subtopic_cols].copy()\n",
    "                  subtopic_metrics_df.rename(columns={'Precision (Subtopics)': 'Precision', 'Recall (Subtopics)': 'Recall', 'F1 (Subtopics)': 'F1'}, inplace=True)\n",
    "                  try:\n",
    "                       subtopic_melted = pd.melt(subtopic_metrics_df, id_vars=required_plot_cols, var_name='Metric Type', value_name='Score')\n",
    "                       subtopic_melted['Metric Type'] = pd.Categorical(subtopic_melted['Metric Type'], categories=['Precision', 'Recall', 'F1'])\n",
    "                  except Exception as melt_e:\n",
    "                       print(f\"  ERROR during subtopic data melting for {key}: {melt_e}\")\n",
    "                       continue\n",
    "\n",
    "                  # --- Generate Subtopic Plot ---\n",
    "                  try:\n",
    "                      # Base plot\n",
    "                      p = (ggplot(topic_melted, aes(x='Metric Type', y='Score', fill=secondary_group_var if secondary_group_var else primary_group_var)) \\\n",
    "                          + geom_col(position=position_dodge(width=0.9), na_rm=True) \\\n",
    "                          + labs(title=f'Subtopic Identification Metrics{plot_title_suffix}',\n",
    "                                 x=(secondary_group_var if secondary_group_var else primary_group_var).replace('_', ' ').title(),\n",
    "                                 y='Score (0-1)', fill='Metric') \\\n",
    "                          + ylim(0, 1.05) \\\n",
    "                          + theme_minimal(base_size=9) \\\n",
    "                          + theme(axis_text_x=element_text(angle=45, hjust=1, size=7),\n",
    "                                  plot_title=element_text(size=11),\n",
    "                                  strip_text=element_text(size=8), # Facet title size\n",
    "                                  figure_size=(max(6, len(summary_df[secondary_group_var if secondary_group_var else primary_group_var].unique()) * (0.6 if secondary_group_var else 0.8)),\n",
    "                                               4 * (len(summary_df[primary_group_var].unique()) if secondary_group_var else 1) )) # Adjust height for facets\n",
    "                          + theme(plot_background=element_rect(fill='white'), panel_background=element_rect(fill='white'))\n",
    "                          )\n",
    "                      # Add facet if it's a nested grouping\n",
    "                      if secondary_group_var and primary_group_var == 'coding_model':\n",
    "                          p += facet_wrap('~coding_model', ncol=1) # Stack facets vertically\n",
    "                      elif secondary_group_var and primary_group_var == 'generating_model':\n",
    "                           p += facet_wrap('~generating_model', ncol=1) # Stack facets vertically\n",
    "\n",
    "                      print(p) # Display the plot\n",
    "\n",
    "                  except Exception as e:\n",
    "                      print(f\"  ERROR generating subtopic plot for {key}: {e}\")\n",
    "\n",
    "    print(\"\\n--- Plotting Complete ---\")\n",
    "\n",
    "# --- Run Analysis and Plotting ---\n",
    "analysis_summary = analyze_coding_results(INPUT_CODING_RESULTS_FILE)\n",
    "\n",
    "plot_evaluation_metrics(analysis_summary)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
